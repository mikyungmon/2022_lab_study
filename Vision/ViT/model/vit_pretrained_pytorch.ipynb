{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq-pb64AvpSG"
   },
   "source": [
    "# ViT_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6790,
     "status": "ok",
     "timestamp": 1647259364592,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "140LMCPeNO3x"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from typing import Optional   # 변수에 None이 들어올 수도 있으면 Optional을 선언하여 사용함\n",
    "from torch import Tensor\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "# from einops import rearrange, reduce, repeat\n",
    "import einops\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# from torchsummaryX import summary\n",
    "import numpy as np\n",
    "from torch.utils import model_zoo\n",
    "from scipy.ndimage import zoom\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from einops import rearrange, reduce, repeat\n",
    "from torchvision.datasets import ImageFolder\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njQSLQP_vzPg"
   },
   "source": [
    "### configs - ViT model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1647259367294,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "zsy9EYESNYVe"
   },
   "outputs": [],
   "source": [
    "\"\"\"configs.py - ViT model configurations, based on:\n",
    "https://github.com/google-research/vision_transformer/blob/master/vit_jax/configs.py\n",
    "\"\"\"\n",
    "\n",
    "def get_base_config():\n",
    "    \"\"\"Base ViT config ViT\"\"\"\n",
    "    return dict(\n",
    "      dim=768,\n",
    "      ff_dim=3072,\n",
    "      num_heads=12,\n",
    "      num_layers=12,\n",
    "      attention_dropout_rate=0.0,\n",
    "      dropout_rate=0.1,\n",
    "      representation_size=768,\n",
    "      classifier='token'\n",
    "    )\n",
    "\n",
    "def get_b16_config():\n",
    "    \"\"\"Returns the ViT-B/16 configuration.\"\"\"\n",
    "    config = get_base_config()\n",
    "    config.update(dict(patches=(16, 16)))\n",
    "    return config\n",
    "\n",
    "def get_b32_config():\n",
    "    \"\"\"Returns the ViT-B/32 configuration.\"\"\"\n",
    "    config = get_b16_config()\n",
    "    config.update(dict(patches=(32, 32)))\n",
    "    return config\n",
    "\n",
    "def get_l16_config():\n",
    "    \"\"\"Returns the ViT-L/16 configuration.\"\"\"\n",
    "    config = get_base_config()\n",
    "    config.update(dict(\n",
    "        patches=(16, 16),\n",
    "        dim=1024,\n",
    "        ff_dim=4096,\n",
    "        num_heads=16,\n",
    "        num_layers=24,\n",
    "        attention_dropout_rate=0.0,\n",
    "        dropout_rate=0.1,\n",
    "        representation_size=1024\n",
    "    ))\n",
    "    return config\n",
    "\n",
    "def get_l32_config():\n",
    "    \"\"\"Returns the ViT-L/32 configuration.\"\"\"\n",
    "    config = get_l16_config()\n",
    "    config.update(dict(patches=(32, 32)))\n",
    "    return config\n",
    "\n",
    "def drop_head_variant(config):\n",
    "    config.update(dict(representation_size=None))\n",
    "    return config\n",
    "\n",
    "\n",
    "PRETRAINED_MODELS = {\n",
    "    'B_16': {\n",
    "      'config': get_b16_config(),\n",
    "      'num_classes': 21843,\n",
    "      'image_size': (224, 224),\n",
    "      'url': \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/B_16.pth\"\n",
    "    },\n",
    "    'B_32': {\n",
    "      'config': get_b32_config(),\n",
    "      'num_classes': 21843,\n",
    "      'image_size': (224, 224),\n",
    "      'url': \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/B_32.pth\"\n",
    "    },\n",
    "    'L_16': {\n",
    "      'config': get_l16_config(),\n",
    "      'num_classes': 21843,\n",
    "      'image_size': (224, 224),\n",
    "      'url': None\n",
    "    },\n",
    "    'L_32': {\n",
    "      'config': get_l32_config(),\n",
    "      'num_classes': 21843,\n",
    "      'image_size': (224, 224),\n",
    "      'url': \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/L_32.pth\"\n",
    "    },\n",
    "    'B_16_imagenet1k': {\n",
    "      'config': drop_head_variant(get_b16_config()),\n",
    "      'num_classes': 1000,\n",
    "      'image_size': (384, 384),\n",
    "      'url': \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/B_16_imagenet1k.pth\"\n",
    "    },\n",
    "    'B_32_imagenet1k': {\n",
    "      'config': drop_head_variant(get_b32_config()),\n",
    "      'num_classes': 1000,\n",
    "      'image_size': (384, 384),\n",
    "      'url': \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/B_32_imagenet1k.pth\"\n",
    "    },\n",
    "    'L_16_imagenet1k': {\n",
    "      'config': drop_head_variant(get_l16_config()),\n",
    "      'num_classes': 1000,\n",
    "      'image_size': (384, 384),\n",
    "      'url': \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/L_16_imagenet1k.pth\"\n",
    "    },\n",
    "    'L_32_imagenet1k': {\n",
    "      'config': drop_head_variant(get_l32_config()),\n",
    "      'num_classes': 1000,\n",
    "      'image_size': (384, 384),\n",
    "      'url': \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/L_32_imagenet1k.pth\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MVGgrQnv66U"
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1647259368613,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "NpgwsovfNc4C"
   },
   "outputs": [],
   "source": [
    "# shape 주석은 img size 224 기준\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels: int = 3, patch_size= 16, emb_size : int = 768, img_size = 384):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.projection = nn.Sequential(nn.Conv2d(in_channels, emb_size, kernel_size = patch_size, stride = patch_size),Rearrange('b e (h) (w) -> b (h w) e'),)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1,1,emb_size))   # torch.randn(1,1,emb_size) : 1행 1열, emb_size(768, 채널) 짜리 평균이 0이고 표준편차가 1인 가우시안 정규분포의 난수로 채워진 텐서 반환 \n",
    "        self.positions = nn.Parameter(torch.randn((img_size // patch_size[0])**2 +1, emb_size))  # (img_size // patch_size)**2는 패치 갯수, +1은 cls_token 으로 늘어난 크기에 맞춰 더한 것\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print('patch emb x:', x)\n",
    "        b = x.shape[0]\n",
    "        # print('b:',b)\n",
    "#         print('patch emb in:',x)\n",
    "        x = self.projection(x)   # [8,768,14,14] -> [8,196,768] \n",
    "        # print('after projection:',x.shape)\n",
    "        \n",
    "        # cls_token을 반복하여 batch size와 크기 맞춰줌(배치 크기 만큼 확장)\n",
    "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)   # [1,1,768] -> [8,1,768]\n",
    "        \n",
    "        # cls token을 input에 추가(concat) \n",
    "        x = torch.cat([cls_tokens,x], dim=1)    # [8,197,768]\n",
    "        \n",
    "         # position embedding 더해줌\n",
    "        x += self.positions   # [197,768](positions) + [8,197,768](x)\n",
    "        # print('positions:',x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1647259369428,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "aomMBigDNc6M"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_size : int = 768, num_heads: int = 8, dropout: float=0):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.num_heads = num_heads\n",
    "        self.keys = nn.Linear(emb_size, emb_size)\n",
    "        self.queries = nn.Linear(emb_size, emb_size)\n",
    "        self.values = nn.Linear(emb_size, emb_size)\n",
    "        self.att_drop = nn.Dropout(dropout)\n",
    "        self.projection = nn.Linear(emb_size, emb_size)\n",
    "        \n",
    "    def forward(self,x ,mask: None): \n",
    "        # queries, keys, values -- [8,8,197,96]\n",
    "        queries = rearrange(self.queries(x), \"b n (h d) -> b h n d\", h=self.num_heads)  # batch, heads, sequence_len, embedding_size(여기서 embedding_size는 embedding_size / n_heads 한 값 인듯) 모양으로 변경\n",
    "        keys = rearrange(self.keys(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
    "        values  = rearrange(self.values(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
    "        \n",
    "        \n",
    "        # einsum 연산을 통해 행렬,벡터의 내적(dot product),외적(outer products), 전치(transpose), 행렬곱 등을 일관성있게 표현 가능\n",
    "        # 쿼리와 키 곱(einops 이용해 자동으로 transpose 후 내적이 진행됨)\n",
    "        energy = torch.einsum('bhqd,bhkd -> bhqk', queries, keys)   # 결과 벡터 모양은 batch, heads, query_len, key_len -- [8,8,197,197]\n",
    "        \n",
    "        if mask is not None:\n",
    "            fill_value = torch.finfo(torch.float32).min\n",
    "            energy.mask_fill()\n",
    "            \n",
    "        scaling = self.emb_size**(1/2)\n",
    "        att = F.softmax(energy, dim=-1) / scaling  # [8,8,197,197]\n",
    "        att = self.att_drop(att)\n",
    "        \n",
    "        # scaling해준 후 얻어진 attention score와 value를 내적\n",
    "        out = torch.einsum('bhal, bhlv -> bhav', att, values)  # [8,8,197,96]\n",
    "        \n",
    "        # emb_size로 rearrange하면 MHA의 output나옴\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')  #  [8,197,768]\n",
    "        \n",
    "        # 최종 output은 linear layer거쳐서 나오게 됨\n",
    "        out = self.projection(out)   \n",
    "      \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1647259370486,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "BxwTE1YINc75"
   },
   "outputs": [],
   "source": [
    "# class ResidualAdd(nn.Module):   # 이 클래스 사용하면 forward() takes 1 positional argument but 2 were given -> 이 오류 계속 남\n",
    "#     def __init__(self,fn):\n",
    "#         super().__init__()\n",
    "#         self.fn = fn\n",
    "        \n",
    "#     def forward(self, **kwargs):  # **kwargs는 keyword argument의 줄임말로 키워드를 제공.딕셔너리 형태로 {'키워드':'특정 값'} 이렇게 함수내부로 전달됨\n",
    "#         res = x\n",
    "#         x = self.fn(x, **kwargs)\n",
    "#         x +=res\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1647259370832,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "Yzk3Fp7jNc-N"
   },
   "outputs": [],
   "source": [
    "# MHA 이후 진행되는 MLP 부분\n",
    "class FeedForwardBlock(nn.Sequential):  \n",
    "    def __init__(self, emb_size: int, expansion: int=4, drop_p: float= 0.):\n",
    "        super().__init__(nn.Linear(emb_size, expansion * emb_size), nn.GELU(), nn.Dropout(drop_p), nn.Linear(expansion*emb_size, emb_size),)    # emb_size확장하고 두번째 linear layer에서 다시 원래의 emb_size로 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647259371709,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "GXO3hW8DNdAd"
   },
   "outputs": [],
   "source": [
    "# class TransformerEncoderBlock(nn.Sequential):     # 이 클래스 사용하면 forward() takes 1 positional argument but 2 were given -> 이 오류 계속 남\n",
    "#     def __init__(self, emb_size: int=768, drop_p: float=0., forward_expansion: int=4, forward_drop_p: float=0., **kwargs):\n",
    "#         super().__init__(ResidualAdd(nn.Sequential(nn.LayerNorm(emb_size), MultiHeadAttention(emb_size, **kwargs), nn.Dropout(drop_p))),\n",
    "#                          ResidualAdd(nn.Sequential(nn.LayerNorm(emb_size), FeedForwardBlock(emb_size, expansion = forward_expansion, drop_p = forward_drop_p), nn.Dropout(drop_p))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647259372326,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "2-5-JQ0ENmcb"
   },
   "outputs": [],
   "source": [
    "# class TransformerEncoder(nn.Sequential):     # 이 클래스 사용하면 forward() takes 1 positional argument but 2 were given -> 이 오류 계속 남\n",
    "#     def __init__(self, depth: int=12, **kwargs):\n",
    "#         super().__init__(*[TransformerEncoderBlock(**kwargs) for _ in range(depth)])  # 앞에 *가 붙은 이유는 인자를 리스트 형식으로 보내는게 아니라 각각 나눠서 보내줘야하기 때문. 인자를 [1,2,3] 넣을 경우 함수에서는 [1,2,3]으로 받지만 *[1,2,3]일 경우 1,2,3으로 각각 나눠진 후 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647259372918,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "fw3IDmegiHWd"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Sequential):\n",
    "    def __init__(self, emb_size: int=768, drop_p: float=0., forward_expansion: int=4, forward_drop_p: float=0., **kwargs):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(emb_size)\n",
    "        self.attention = MultiHeadAttention(emb_size, **kwargs)\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "        self.norm2 = nn.LayerNorm(emb_size)\n",
    "        self.mlp = FeedForwardBlock(emb_size, expansion = forward_expansion, drop_p = forward_drop_p)\n",
    "        \n",
    "    def forward(self,x,mask=None):\n",
    "        h = self.norm1(x)\n",
    "        h = self.attention(h, mask=None)\n",
    "        h = self.dropout(h)\n",
    "        x = x+h\n",
    "        h = self.norm2(x)\n",
    "        h = self.mlp(h)\n",
    "        h = self.dropout(h)\n",
    "        x = x+h\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647259374239,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "8V0j3pCHiHZD"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, depth: int=12, **kwargs):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([TransformerEncoderBlock(**kwargs) for _ in range(depth)])\n",
    "\n",
    "    def forward(self,x, mask=None):\n",
    "        for block in self.blocks:\n",
    "            x = block(x,mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1647259375544,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "JWQ3HTPCNnXW"
   },
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, name = None, pretrained: bool=False, patch_size: int=16, emb_size: int=768, ff_dim = 3072, num_heads: int=12, \n",
    "                 attention_dropout_rate: float=0., dropout_rate = 0.1, in_channels: int=3,image_size: int=384, depth: int=12, n_classes: int=2, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        if name is None:\n",
    "            check_msg = 'must specify name of pretrained model'\n",
    "            assert not pretrained, check_msg    # assert - 가정 설정문, 뒤의 조건이 true가 아니면 AssertError발생시킴\n",
    "            assert not resize_positional_embedding, check_msg  \n",
    "            if n_classes is None:\n",
    "                n_classes = 2\n",
    "            if image_size is None:\n",
    "                image_size = 384\n",
    "        \n",
    "        else:  # load pretrained model\n",
    "            assert name in PRETRAINED_MODELS.keys(), \\\n",
    "                'name should be in: ' + ', '.join(PRETRAINED_MODELS.keys())\n",
    "            config = PRETRAINED_MODELS[name]['config']\n",
    "            patch_size = config['patches']\n",
    "            dim = config['dim']\n",
    "            ff_dim = config['ff_dim']\n",
    "            num_heads = config['num_heads']\n",
    "            depth = config['num_layers']\n",
    "            attention_dropout_rate = config['attention_dropout_rate']\n",
    "            dropout_rate = config['dropout_rate']\n",
    "#             representation_size = config['representation_size']\n",
    "#             classifier = config['classifier']\n",
    "            \n",
    "            if image_size is None:\n",
    "                image_size = PRETRAINED_MODELS[name]['image_size']\n",
    "            \n",
    "            if n_classes is None:\n",
    "                n_classes = PRETRAINED_MODELS[name]['num_classes']\n",
    "                \n",
    "#         self.image_size = image_size\n",
    "        \n",
    "        # patch embedding\n",
    "        print(patch_size)\n",
    "        self.patch_embedding = PatchEmbedding(in_channels, patch_size, emb_size, image_size) \n",
    "                   \n",
    "        # print('self.transformer input:',TransformerEncoder(depth, emb_size=emb_size, **kwargs))\n",
    "        # transformer\n",
    "        self.transformer = TransformerEncoder(depth, emb_size=emb_size, **kwargs)\n",
    "        \n",
    "        \n",
    "        # classifier head\n",
    "#         self.classification = ClassificationHead(emb_size, n_classes)\n",
    "        self.norm = nn.LayerNorm(emb_size,eps=1e-6)\n",
    "        self.fc = nn.Linear(emb_size ,n_classes)\n",
    "        \n",
    "        # initialize weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        # load pretrained model\n",
    "        if pretrained:\n",
    "            pretrained_num_channels = 3\n",
    "            pretrained_num_classes = PRETRAINED_MODELS[name]['num_classes']\n",
    "            pretrained_image_size = PRETRAINED_MODELS[name]['image_size']\n",
    "#             load_pretrained_weights(name, None)\n",
    "            \n",
    "            url = PRETRAINED_MODELS[name]['url']\n",
    "            if url:\n",
    "                state_dict = model_zoo.load_url(url)   # model_zoo.load_url - 주어진 url에서 torch 직렬화된 개체를 로드\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f'pretrained model for {name} has not yet been released')   # raise - 예외 에러 발생 시키기, ValueError은 키워드\n",
    "\n",
    "            expected_missing_keys = []\n",
    "            if pretrained_num_channels != in_channels and 'patch_embedding.projection.weight' in state_dict:\n",
    "                expected_missing_keys +=['patch_embedding.projection.weight', 'projection.bias']\n",
    "\n",
    "            if pretrained_num_classes != n_classes and 'fc.weight' in state_dict:\n",
    "                expected_missing_keys +=['fc.weight', 'fc.bias']\n",
    "\n",
    "            for key in expected_missing_keys:\n",
    "#                 print(state_dict)\n",
    "                state_dict.pop(key)    # pop - 리스트의 마지막 요소 꺼내고 삭제\n",
    "\n",
    "            # resize positional embedding\n",
    "            if pretrained_image_size != image_size in state_dict:\n",
    "                posemb = state_dict['patch_embedding.positions']   # static_dict은 torch.save처럼 모델 저장, 각 layer마다 텐서로 매핑되는 매개변수(예를 들어 가중치, 편향 등)를 python dictionary 타입으로 저장한 객체(한마디로 모델 구조에 맞게 각 레이어마다 매개변수를 텐서형태로 매핑해서 dictionary 형태로 저장하는 것)\n",
    "                posemb_tok, posemb_grid = posemb[:, :1], posemb[0, 1:]  # posemb에 어떤형태로 값이 들어간지 모르겠음\n",
    "\n",
    "                # get old and new grid sizes\n",
    "                grid_size_old = int(np.sqrt(len(posemb_grid)))\n",
    "                grid_size_new = int(np.sqrt(ntok_new))\n",
    "                posemb_grid = posemb_grid.reshape(grid_size_old, grid_size_old, -1)   # 불러온 그리드로 reshape해주고?\n",
    "\n",
    "                # rescale grid\n",
    "                zoom_factor = (grid_size_new / grid_size_old, grid_size_new / grid_size_old,1)\n",
    "                posemb_grid = zoom(posemb_grid, zoom_factor, order =1)   # zoom은 보간해주는거? 줌 패턴으로 그리드를 늘림\n",
    "                posemb_grid = posemb_grid.reshape(1, grid_size_new * grid_size_new, -1)  # 그리드 사이즈에 맞게 reshape\n",
    "                posemb_grid = torch.from_numpy(posemb_grid)\n",
    "\n",
    "                # deal with class token and return \n",
    "                posemb = torch.cat([posemb_tok, posemb_grid], dim=1)\n",
    "\n",
    "                state_dict['patch_embedding.positions'] = posemb\n",
    "                \n",
    "            self.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    def init_weights(self):\n",
    "        def _init(m):\n",
    "            if isinstance(m, nn.Linear):   # m이 nn.linear인지 확인..?\n",
    "                nn.init.xavier_uniform_(m.weight)  # _trunc_normal(m.weight, std=0.02)  # from .initialization import _trunc_normal\n",
    "                if hasattr(m, 'bias') and m.bias is not None:   # hasattr- 변수가 있는지 확인함. ex) hasattr(cls,'b') -> cls에 b라는 멤버가 있는지 확인\n",
    "                    nn.init.normal_(m.bias, std=1e-6)  # nn.init.constant(m.bias, 0)\n",
    "        self.apply(_init)\n",
    "        nn.init.constant_(self.fc.weight, 0)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.normal_(self.patch_embedding.positions, std=0.02)  # _trunc_normal(self.positional_embedding.pos_embedding, std=0.02)\n",
    "#         nn.init.constant_(self.class_token, 0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # print('vit input:',x.shape)\n",
    "        x = self.patch_embedding(x)   \n",
    "        # print('after patch emb x:',x.shape)\n",
    "        x = self.transformer(x)   ################오류\n",
    "#         x = self.classification(x)\n",
    "        x = self.norm(x)[:,0]  # class token만\n",
    "        x = self.fc(x)\n",
    "#             if hasattr(self, 'class_token'):\n",
    "#                 x = torch.cat((self.class_token.expand(b,-1,-1),x), dim=1)\n",
    "#             if hasattr(self,'positional_embedding'):\n",
    "#                 x = self.positional_embedding(x)\n",
    "#             x = self.transformer(x)\n",
    "#             if hasattr(self,'pre_logits'):\n",
    "#                 x = self.pre_logits(x)\n",
    "#                 x = torch.tanh(x)\n",
    "#             if hasattr(self,'fc'):\n",
    "#                 x = self.norm(x)[:,0]\n",
    "#                 x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyMZGlvmv-fj"
   },
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1647259409075,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "RL6vaKiI1l1J"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.Resize((384,384)),transforms.ToTensor()])\n",
    "val_transform = transforms.Compose([transforms.Resize((384,384)),transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.Resize((384,384)),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 20632,
     "status": "ok",
     "timestamp": 1647259430404,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "eCgjxssD0lfZ"
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder('F:\\\\mk\\\\chest_xray\\\\train\\\\',  train_transform)\n",
    "val_dataset = ImageFolder('F:\\\\mk\\\\chest_xray\\\\val\\\\',  val_transform)\n",
    "test_dataset = ImageFolder('F:\\\\mk\\\\chest_xray\\\\test\\\\', test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647259430404,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "xVMfWLju0lhy",
    "outputId": "50722e6b-8996-4cc4-8e69-71abb707d751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "classes = train_dataset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1647259430778,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "G2GQ67XG0ljx",
    "outputId": "dc9172e3-c355-46ca-8bb4-5373d9acc423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num  0\n",
      "data  tensor([[[0.0902, 0.0824, 0.0784,  ..., 0.3725, 0.3725, 0.3725],\n",
      "         [0.0902, 0.0863, 0.0784,  ..., 0.3725, 0.3725, 0.3765],\n",
      "         [0.0863, 0.0824, 0.0863,  ..., 0.3725, 0.3725, 0.3725],\n",
      "         ...,\n",
      "         [0.1333, 0.1373, 0.1373,  ..., 0.3216, 0.3255, 0.3255],\n",
      "         [0.1608, 0.1608, 0.1608,  ..., 0.3882, 0.3843, 0.3922],\n",
      "         [0.1922, 0.1922, 0.1882,  ..., 0.4588, 0.4549, 0.4588]],\n",
      "\n",
      "        [[0.0902, 0.0824, 0.0784,  ..., 0.3725, 0.3725, 0.3725],\n",
      "         [0.0902, 0.0863, 0.0784,  ..., 0.3725, 0.3725, 0.3765],\n",
      "         [0.0863, 0.0824, 0.0863,  ..., 0.3725, 0.3725, 0.3725],\n",
      "         ...,\n",
      "         [0.1333, 0.1373, 0.1373,  ..., 0.3216, 0.3255, 0.3255],\n",
      "         [0.1608, 0.1608, 0.1608,  ..., 0.3882, 0.3843, 0.3922],\n",
      "         [0.1922, 0.1922, 0.1882,  ..., 0.4588, 0.4549, 0.4588]],\n",
      "\n",
      "        [[0.0902, 0.0824, 0.0784,  ..., 0.3725, 0.3725, 0.3725],\n",
      "         [0.0902, 0.0863, 0.0784,  ..., 0.3725, 0.3725, 0.3765],\n",
      "         [0.0863, 0.0824, 0.0863,  ..., 0.3725, 0.3725, 0.3725],\n",
      "         ...,\n",
      "         [0.1333, 0.1373, 0.1373,  ..., 0.3216, 0.3255, 0.3255],\n",
      "         [0.1608, 0.1608, 0.1608,  ..., 0.3882, 0.3843, 0.3922],\n",
      "         [0.1922, 0.1922, 0.1882,  ..., 0.4588, 0.4549, 0.4588]]])\n",
      "label  0\n"
     ]
    }
   ],
   "source": [
    "for num, value in enumerate(train_dataset): \n",
    "    data, label = value \n",
    "    print('num ', num)\n",
    "    print('data ', data)\n",
    "    print('label ', label)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1647259437157,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "PrpZIy81IKA2"
   },
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_dataset,batch_size = 6, shuffle=True, num_workers=0)\n",
    "val_data_loader = DataLoader(val_dataset,batch_size = 6, shuffle=True, num_workers=0)\n",
    "test_data_loader = DataLoader(test_dataset,batch_size= 6, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubhajteGwBQJ"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Early_Stopping:\n",
    "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pth'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
    "                            Default: 7\n",
    "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
    "                            Default: False\n",
    "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
    "                            Default: 0\n",
    "            path (str): checkpoint저장 경로\n",
    "                            Default: 'checkpoint.pth'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model,path):\n",
    "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            \n",
    "        # 모델 저장\n",
    "        torch.save(model.state_dict(), path+\"vit_model.pth\")\n",
    "\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "82417fe9c98647f1ad03d1a7fe02ccf0",
      "70df47a42d8a47668bf09624ecf5c7d5",
      "86c92460d09c478cb7cc756886faaa4b",
      "0577ffd73e934a51a6ade33a84f0e5a3",
      "44b501daa7304efab202931ae5123f13",
      "933fcfe2ce35408baa6c2613cb29229a",
      "7b869e361b7949df8abbc53cfdc672ab",
      "e58f83284fa94eefb9df3dbccb44747d",
      "2a9a68e3453f4f12986038e8d062e10a",
      "14da05d2c90d4654b615a02b06f3300c",
      "899749374ec9409eb47fe0cfffa92d63"
     ]
    },
    "executionInfo": {
     "elapsed": 26773,
     "status": "ok",
     "timestamp": 1647259471506,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "Hf6hKA5DRIVk",
    "outputId": "114e40df-b613-44f5-e672-43c2d61ad645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 24, 24]         590,592\n",
      "         Rearrange-2             [-1, 576, 768]               0\n",
      "    PatchEmbedding-3             [-1, 577, 768]               0\n",
      "         LayerNorm-4             [-1, 577, 768]           1,536\n",
      "            Linear-5             [-1, 577, 768]         590,592\n",
      "            Linear-6             [-1, 577, 768]         590,592\n",
      "            Linear-7             [-1, 577, 768]         590,592\n",
      "           Dropout-8          [-1, 8, 577, 577]               0\n",
      "            Linear-9             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-10             [-1, 577, 768]               0\n",
      "          Dropout-11             [-1, 577, 768]               0\n",
      "        LayerNorm-12             [-1, 577, 768]           1,536\n",
      "           Linear-13            [-1, 577, 3072]       2,362,368\n",
      "             GELU-14            [-1, 577, 3072]               0\n",
      "          Dropout-15            [-1, 577, 3072]               0\n",
      "           Linear-16             [-1, 577, 768]       2,360,064\n",
      "          Dropout-17             [-1, 577, 768]               0\n",
      "        LayerNorm-18             [-1, 577, 768]           1,536\n",
      "           Linear-19             [-1, 577, 768]         590,592\n",
      "           Linear-20             [-1, 577, 768]         590,592\n",
      "           Linear-21             [-1, 577, 768]         590,592\n",
      "          Dropout-22          [-1, 8, 577, 577]               0\n",
      "           Linear-23             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-24             [-1, 577, 768]               0\n",
      "          Dropout-25             [-1, 577, 768]               0\n",
      "        LayerNorm-26             [-1, 577, 768]           1,536\n",
      "           Linear-27            [-1, 577, 3072]       2,362,368\n",
      "             GELU-28            [-1, 577, 3072]               0\n",
      "          Dropout-29            [-1, 577, 3072]               0\n",
      "           Linear-30             [-1, 577, 768]       2,360,064\n",
      "          Dropout-31             [-1, 577, 768]               0\n",
      "        LayerNorm-32             [-1, 577, 768]           1,536\n",
      "           Linear-33             [-1, 577, 768]         590,592\n",
      "           Linear-34             [-1, 577, 768]         590,592\n",
      "           Linear-35             [-1, 577, 768]         590,592\n",
      "          Dropout-36          [-1, 8, 577, 577]               0\n",
      "           Linear-37             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-38             [-1, 577, 768]               0\n",
      "          Dropout-39             [-1, 577, 768]               0\n",
      "        LayerNorm-40             [-1, 577, 768]           1,536\n",
      "           Linear-41            [-1, 577, 3072]       2,362,368\n",
      "             GELU-42            [-1, 577, 3072]               0\n",
      "          Dropout-43            [-1, 577, 3072]               0\n",
      "           Linear-44             [-1, 577, 768]       2,360,064\n",
      "          Dropout-45             [-1, 577, 768]               0\n",
      "        LayerNorm-46             [-1, 577, 768]           1,536\n",
      "           Linear-47             [-1, 577, 768]         590,592\n",
      "           Linear-48             [-1, 577, 768]         590,592\n",
      "           Linear-49             [-1, 577, 768]         590,592\n",
      "          Dropout-50          [-1, 8, 577, 577]               0\n",
      "           Linear-51             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-52             [-1, 577, 768]               0\n",
      "          Dropout-53             [-1, 577, 768]               0\n",
      "        LayerNorm-54             [-1, 577, 768]           1,536\n",
      "           Linear-55            [-1, 577, 3072]       2,362,368\n",
      "             GELU-56            [-1, 577, 3072]               0\n",
      "          Dropout-57            [-1, 577, 3072]               0\n",
      "           Linear-58             [-1, 577, 768]       2,360,064\n",
      "          Dropout-59             [-1, 577, 768]               0\n",
      "        LayerNorm-60             [-1, 577, 768]           1,536\n",
      "           Linear-61             [-1, 577, 768]         590,592\n",
      "           Linear-62             [-1, 577, 768]         590,592\n",
      "           Linear-63             [-1, 577, 768]         590,592\n",
      "          Dropout-64          [-1, 8, 577, 577]               0\n",
      "           Linear-65             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-66             [-1, 577, 768]               0\n",
      "          Dropout-67             [-1, 577, 768]               0\n",
      "        LayerNorm-68             [-1, 577, 768]           1,536\n",
      "           Linear-69            [-1, 577, 3072]       2,362,368\n",
      "             GELU-70            [-1, 577, 3072]               0\n",
      "          Dropout-71            [-1, 577, 3072]               0\n",
      "           Linear-72             [-1, 577, 768]       2,360,064\n",
      "          Dropout-73             [-1, 577, 768]               0\n",
      "        LayerNorm-74             [-1, 577, 768]           1,536\n",
      "           Linear-75             [-1, 577, 768]         590,592\n",
      "           Linear-76             [-1, 577, 768]         590,592\n",
      "           Linear-77             [-1, 577, 768]         590,592\n",
      "          Dropout-78          [-1, 8, 577, 577]               0\n",
      "           Linear-79             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-80             [-1, 577, 768]               0\n",
      "          Dropout-81             [-1, 577, 768]               0\n",
      "        LayerNorm-82             [-1, 577, 768]           1,536\n",
      "           Linear-83            [-1, 577, 3072]       2,362,368\n",
      "             GELU-84            [-1, 577, 3072]               0\n",
      "          Dropout-85            [-1, 577, 3072]               0\n",
      "           Linear-86             [-1, 577, 768]       2,360,064\n",
      "          Dropout-87             [-1, 577, 768]               0\n",
      "        LayerNorm-88             [-1, 577, 768]           1,536\n",
      "           Linear-89             [-1, 577, 768]         590,592\n",
      "           Linear-90             [-1, 577, 768]         590,592\n",
      "           Linear-91             [-1, 577, 768]         590,592\n",
      "          Dropout-92          [-1, 8, 577, 577]               0\n",
      "           Linear-93             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-94             [-1, 577, 768]               0\n",
      "          Dropout-95             [-1, 577, 768]               0\n",
      "        LayerNorm-96             [-1, 577, 768]           1,536\n",
      "           Linear-97            [-1, 577, 3072]       2,362,368\n",
      "             GELU-98            [-1, 577, 3072]               0\n",
      "          Dropout-99            [-1, 577, 3072]               0\n",
      "          Linear-100             [-1, 577, 768]       2,360,064\n",
      "         Dropout-101             [-1, 577, 768]               0\n",
      "       LayerNorm-102             [-1, 577, 768]           1,536\n",
      "          Linear-103             [-1, 577, 768]         590,592\n",
      "          Linear-104             [-1, 577, 768]         590,592\n",
      "          Linear-105             [-1, 577, 768]         590,592\n",
      "         Dropout-106          [-1, 8, 577, 577]               0\n",
      "          Linear-107             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-108             [-1, 577, 768]               0\n",
      "         Dropout-109             [-1, 577, 768]               0\n",
      "       LayerNorm-110             [-1, 577, 768]           1,536\n",
      "          Linear-111            [-1, 577, 3072]       2,362,368\n",
      "            GELU-112            [-1, 577, 3072]               0\n",
      "         Dropout-113            [-1, 577, 3072]               0\n",
      "          Linear-114             [-1, 577, 768]       2,360,064\n",
      "         Dropout-115             [-1, 577, 768]               0\n",
      "       LayerNorm-116             [-1, 577, 768]           1,536\n",
      "          Linear-117             [-1, 577, 768]         590,592\n",
      "          Linear-118             [-1, 577, 768]         590,592\n",
      "          Linear-119             [-1, 577, 768]         590,592\n",
      "         Dropout-120          [-1, 8, 577, 577]               0\n",
      "          Linear-121             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-122             [-1, 577, 768]               0\n",
      "         Dropout-123             [-1, 577, 768]               0\n",
      "       LayerNorm-124             [-1, 577, 768]           1,536\n",
      "          Linear-125            [-1, 577, 3072]       2,362,368\n",
      "            GELU-126            [-1, 577, 3072]               0\n",
      "         Dropout-127            [-1, 577, 3072]               0\n",
      "          Linear-128             [-1, 577, 768]       2,360,064\n",
      "         Dropout-129             [-1, 577, 768]               0\n",
      "       LayerNorm-130             [-1, 577, 768]           1,536\n",
      "          Linear-131             [-1, 577, 768]         590,592\n",
      "          Linear-132             [-1, 577, 768]         590,592\n",
      "          Linear-133             [-1, 577, 768]         590,592\n",
      "         Dropout-134          [-1, 8, 577, 577]               0\n",
      "          Linear-135             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-136             [-1, 577, 768]               0\n",
      "         Dropout-137             [-1, 577, 768]               0\n",
      "       LayerNorm-138             [-1, 577, 768]           1,536\n",
      "          Linear-139            [-1, 577, 3072]       2,362,368\n",
      "            GELU-140            [-1, 577, 3072]               0\n",
      "         Dropout-141            [-1, 577, 3072]               0\n",
      "          Linear-142             [-1, 577, 768]       2,360,064\n",
      "         Dropout-143             [-1, 577, 768]               0\n",
      "       LayerNorm-144             [-1, 577, 768]           1,536\n",
      "          Linear-145             [-1, 577, 768]         590,592\n",
      "          Linear-146             [-1, 577, 768]         590,592\n",
      "          Linear-147             [-1, 577, 768]         590,592\n",
      "         Dropout-148          [-1, 8, 577, 577]               0\n",
      "          Linear-149             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-150             [-1, 577, 768]               0\n",
      "         Dropout-151             [-1, 577, 768]               0\n",
      "       LayerNorm-152             [-1, 577, 768]           1,536\n",
      "          Linear-153            [-1, 577, 3072]       2,362,368\n",
      "            GELU-154            [-1, 577, 3072]               0\n",
      "         Dropout-155            [-1, 577, 3072]               0\n",
      "          Linear-156             [-1, 577, 768]       2,360,064\n",
      "         Dropout-157             [-1, 577, 768]               0\n",
      "       LayerNorm-158             [-1, 577, 768]           1,536\n",
      "          Linear-159             [-1, 577, 768]         590,592\n",
      "          Linear-160             [-1, 577, 768]         590,592\n",
      "          Linear-161             [-1, 577, 768]         590,592\n",
      "         Dropout-162          [-1, 8, 577, 577]               0\n",
      "          Linear-163             [-1, 577, 768]         590,592\n",
      "MultiHeadAttention-164             [-1, 577, 768]               0\n",
      "         Dropout-165             [-1, 577, 768]               0\n",
      "       LayerNorm-166             [-1, 577, 768]           1,536\n",
      "          Linear-167            [-1, 577, 3072]       2,362,368\n",
      "            GELU-168            [-1, 577, 3072]               0\n",
      "         Dropout-169            [-1, 577, 3072]               0\n",
      "          Linear-170             [-1, 577, 768]       2,360,064\n",
      "         Dropout-171             [-1, 577, 768]               0\n",
      "TransformerEncoder-172             [-1, 577, 768]               0\n",
      "       LayerNorm-173             [-1, 577, 768]           1,536\n",
      "          Linear-174                    [-1, 2]           1,538\n",
      "================================================================\n",
      "Total params: 85,648,130\n",
      "Trainable params: 85,648,130\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 1153.28\n",
      "Params size (MB): 326.72\n",
      "Estimated Total Size (MB): 1481.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_vit = ViT(name ='B_16_imagenet1k', pretrained=True, emb_size=768, ff_dim=3072, num_heads=12, \n",
    "                attention_dropout_rate=0.0, dropout_rate = 0.1, in_channels=3,image_size=384, depth=12, n_classes=2 ).cuda()\n",
    "# USE_CUDA = torch.cuda.is_available()  \n",
    "# DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "# print('device:',DEVICE) \n",
    "# batch_size = 64   \n",
    "epochs = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_vit.parameters(), lr=learning_rate)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "\n",
    "summary(model_vit,(3,384,384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1647259504456,
     "user": {
      "displayName": "콩콩",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09214712120273515156"
     },
     "user_tz": -540
    },
    "id": "1XJACS-BRKBJ"
   },
   "outputs": [],
   "source": [
    "earlystop_patient = 40\n",
    "earlystopping = Early_Stopping(patience=earlystop_patient,verbose=True)\n",
    "\n",
    "def train_val(model_vit, train_data_loader, val_data_loader, optimizer, epochs):\n",
    "    # train\n",
    "    val_loss = []\n",
    "    for epoch in range(1,epochs+1):\n",
    "        model_vit.train()\n",
    "        for batch_idx,(img,target) in enumerate(train_data_loader):\n",
    "            img, target = img.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model_vit(img)\n",
    "            loss = F.cross_entropy(output,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0 :\n",
    "                print(\"[Epoch %d/%d] [Batch %d/%d] [loss: %.6f]\" % (epoch, epochs, batch_idx, len(train_data_loader), loss.item()))\n",
    "#                 print('train epoch : {}[{}/{} ({: .0f}%)]\\tloss:{:.6f}'.format(epoch, len(img), len(train_data_loader.dataset),\n",
    "#                                                                            100* batch_idx / len(train_data_loader.dataset),loss.item()))\n",
    "\n",
    "        print(\"-----[Epoch %d/%d] [avg_train_loss: %f]-----\" % (epoch, epochs, np.average(loss.item())))\n",
    "     \n",
    "        # validation          \n",
    "        model_vit.eval()\n",
    "        save_path = 'F:\\\\mk\\\\save_model\\\\'\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i,(v_imgs,v_targets) in enumerate(val_data_loader):\n",
    "                img, target = v_imgs.cuda(), v_targets.cuda()\n",
    "                output = model_vit(img)\n",
    "\n",
    "                # 배치 오차를 합산\n",
    "            \n",
    "                validation_loss = F.cross_entropy(output, target, reduction='sum').item()\n",
    "                validation_loss += validation_loss\n",
    "                print(\"validation loss: {}\".format(validation_loss))\n",
    "                val_loss.append(validation_loss)\n",
    "\n",
    "                # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
    "#                 pred = output.max(1, keepdim=True)[1]\n",
    "#                 correct_val = pred.eq(target.view_as(pred)).sum().item()\n",
    "#                 correct_val + = correct_val\n",
    "        \n",
    "\n",
    "\n",
    "        valid_loss=np.average(val_loss)\n",
    "        print(\"-----[val_avg_loss %f]-----\" % valid_loss)\n",
    "\n",
    "        # loss 떨어지면 model 저장\n",
    "        earlystopping(validation_loss,model_vit,path=save_path)\n",
    "\n",
    "        if earlystopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/100] [Batch 0/870] [loss: 0.095607]\n",
      "[Epoch 1/100] [Batch 100/870] [loss: 0.018003]\n",
      "[Epoch 1/100] [Batch 200/870] [loss: 0.085457]\n",
      "[Epoch 1/100] [Batch 300/870] [loss: 0.153195]\n",
      "[Epoch 1/100] [Batch 400/870] [loss: 0.013461]\n",
      "[Epoch 1/100] [Batch 500/870] [loss: 0.004137]\n",
      "[Epoch 1/100] [Batch 600/870] [loss: 0.068757]\n",
      "[Epoch 1/100] [Batch 700/870] [loss: 0.091549]\n",
      "[Epoch 1/100] [Batch 800/870] [loss: 0.020403]\n",
      "-----[Epoch 1/100] [avg_train_loss: 0.003539]-----\n",
      "validation loss: 13.204612731933594\n",
      "validation loss: 11.928382873535156\n",
      "validation loss: 10.538419723510742\n",
      "-----[val_avg_loss 11.890472]-----\n",
      "Validation loss decreased (inf --> 10.538420).  Saving model ...\n",
      "[Epoch 2/100] [Batch 0/870] [loss: 0.309153]\n",
      "[Epoch 2/100] [Batch 100/870] [loss: 0.042092]\n",
      "[Epoch 2/100] [Batch 200/870] [loss: 0.077056]\n",
      "[Epoch 2/100] [Batch 300/870] [loss: 0.209545]\n",
      "[Epoch 2/100] [Batch 400/870] [loss: 0.158199]\n",
      "[Epoch 2/100] [Batch 500/870] [loss: 0.028819]\n",
      "[Epoch 2/100] [Batch 600/870] [loss: 0.015989]\n",
      "[Epoch 2/100] [Batch 700/870] [loss: 0.143844]\n",
      "[Epoch 2/100] [Batch 800/870] [loss: 0.494445]\n",
      "-----[Epoch 2/100] [avg_train_loss: 0.023863]-----\n",
      "validation loss: 15.575201034545898\n",
      "validation loss: 8.735137939453125\n",
      "validation loss: 1.7752023935317993\n",
      "-----[val_avg_loss 10.292826]-----\n",
      "Validation loss decreased (10.538420 --> 1.775202).  Saving model ...\n",
      "[Epoch 3/100] [Batch 0/870] [loss: 0.010755]\n",
      "[Epoch 3/100] [Batch 100/870] [loss: 0.040622]\n",
      "[Epoch 3/100] [Batch 200/870] [loss: 0.151013]\n",
      "[Epoch 3/100] [Batch 300/870] [loss: 0.047193]\n",
      "[Epoch 3/100] [Batch 400/870] [loss: 0.021917]\n",
      "[Epoch 3/100] [Batch 500/870] [loss: 0.018808]\n",
      "[Epoch 3/100] [Batch 600/870] [loss: 0.016020]\n",
      "[Epoch 3/100] [Batch 700/870] [loss: 0.004133]\n",
      "[Epoch 3/100] [Batch 800/870] [loss: 0.014912]\n",
      "-----[Epoch 3/100] [avg_train_loss: 0.040813]-----\n",
      "validation loss: 1.00652277469635\n",
      "validation loss: 7.715878009796143\n",
      "validation loss: 2.268117666244507\n",
      "-----[val_avg_loss 8.083053]-----\n",
      "EarlyStopping counter: 1 out of 40\n",
      "[Epoch 4/100] [Batch 0/870] [loss: 0.391047]\n",
      "[Epoch 4/100] [Batch 100/870] [loss: 0.018074]\n",
      "[Epoch 4/100] [Batch 200/870] [loss: 0.001042]\n",
      "[Epoch 4/100] [Batch 300/870] [loss: 0.299204]\n",
      "[Epoch 4/100] [Batch 400/870] [loss: 0.103235]\n",
      "[Epoch 4/100] [Batch 500/870] [loss: 0.092488]\n",
      "[Epoch 4/100] [Batch 600/870] [loss: 0.104587]\n",
      "[Epoch 4/100] [Batch 700/870] [loss: 0.105103]\n",
      "[Epoch 4/100] [Batch 800/870] [loss: 0.030513]\n",
      "-----[Epoch 4/100] [avg_train_loss: 0.034704]-----\n",
      "validation loss: 2.8128411769866943\n",
      "validation loss: 10.634432792663574\n",
      "validation loss: 1.3271403312683105\n",
      "-----[val_avg_loss 7.293491]-----\n",
      "Validation loss decreased (1.775202 --> 1.327140).  Saving model ...\n",
      "[Epoch 5/100] [Batch 0/870] [loss: 0.016270]\n",
      "[Epoch 5/100] [Batch 100/870] [loss: 0.050923]\n",
      "[Epoch 5/100] [Batch 200/870] [loss: 0.539015]\n",
      "[Epoch 5/100] [Batch 300/870] [loss: 0.692375]\n",
      "[Epoch 5/100] [Batch 400/870] [loss: 0.060559]\n",
      "[Epoch 5/100] [Batch 500/870] [loss: 0.134040]\n",
      "[Epoch 5/100] [Batch 600/870] [loss: 0.052974]\n",
      "[Epoch 5/100] [Batch 700/870] [loss: 0.015006]\n",
      "[Epoch 5/100] [Batch 800/870] [loss: 0.118011]\n",
      "-----[Epoch 5/100] [avg_train_loss: 0.000758]-----\n",
      "validation loss: 22.745372772216797\n",
      "validation loss: 13.546477317810059\n",
      "validation loss: 10.150870323181152\n",
      "-----[val_avg_loss 8.930974]-----\n",
      "EarlyStopping counter: 1 out of 40\n",
      "[Epoch 6/100] [Batch 0/870] [loss: 0.014227]\n",
      "[Epoch 6/100] [Batch 100/870] [loss: 0.106799]\n",
      "[Epoch 6/100] [Batch 200/870] [loss: 0.147981]\n",
      "[Epoch 6/100] [Batch 300/870] [loss: 0.474073]\n",
      "[Epoch 6/100] [Batch 400/870] [loss: 0.014113]\n",
      "[Epoch 6/100] [Batch 500/870] [loss: 0.002996]\n",
      "[Epoch 6/100] [Batch 600/870] [loss: 0.016157]\n",
      "[Epoch 6/100] [Batch 700/870] [loss: 0.009030]\n",
      "[Epoch 6/100] [Batch 800/870] [loss: 0.068364]\n",
      "-----[Epoch 6/100] [avg_train_loss: 0.010751]-----\n",
      "validation loss: 10.33631706237793\n",
      "validation loss: 10.014522552490234\n",
      "validation loss: 10.840121269226074\n",
      "-----[val_avg_loss 9.175309]-----\n",
      "EarlyStopping counter: 2 out of 40\n",
      "[Epoch 7/100] [Batch 0/870] [loss: 0.036045]\n",
      "[Epoch 7/100] [Batch 100/870] [loss: 0.149022]\n",
      "[Epoch 7/100] [Batch 200/870] [loss: 0.012760]\n",
      "[Epoch 7/100] [Batch 300/870] [loss: 0.062595]\n",
      "[Epoch 7/100] [Batch 400/870] [loss: 0.059993]\n",
      "[Epoch 7/100] [Batch 500/870] [loss: 0.018555]\n",
      "[Epoch 7/100] [Batch 600/870] [loss: 0.015842]\n",
      "[Epoch 7/100] [Batch 700/870] [loss: 0.008083]\n",
      "[Epoch 7/100] [Batch 800/870] [loss: 0.010512]\n",
      "-----[Epoch 7/100] [avg_train_loss: 0.466513]-----\n",
      "validation loss: 1.8914308547973633\n",
      "validation loss: 5.336620807647705\n",
      "validation loss: 1.2729169130325317\n",
      "-----[val_avg_loss 8.269359]-----\n",
      "Validation loss decreased (1.327140 --> 1.272917).  Saving model ...\n",
      "[Epoch 8/100] [Batch 0/870] [loss: 0.273774]\n",
      "[Epoch 8/100] [Batch 100/870] [loss: 0.167639]\n",
      "[Epoch 8/100] [Batch 200/870] [loss: 0.085259]\n",
      "[Epoch 8/100] [Batch 300/870] [loss: 0.072331]\n",
      "[Epoch 8/100] [Batch 400/870] [loss: 0.020125]\n",
      "[Epoch 8/100] [Batch 500/870] [loss: 0.166574]\n",
      "[Epoch 8/100] [Batch 600/870] [loss: 0.075539]\n",
      "[Epoch 8/100] [Batch 700/870] [loss: 0.132690]\n",
      "[Epoch 8/100] [Batch 800/870] [loss: 0.150635]\n",
      "-----[Epoch 8/100] [avg_train_loss: 0.255245]-----\n",
      "validation loss: 1.6786906719207764\n",
      "validation loss: 8.665374755859375\n",
      "validation loss: 2.6427359580993652\n",
      "-----[val_avg_loss 7.776806]-----\n",
      "EarlyStopping counter: 1 out of 40\n",
      "[Epoch 9/100] [Batch 0/870] [loss: 0.121924]\n",
      "[Epoch 9/100] [Batch 100/870] [loss: 0.449150]\n",
      "[Epoch 9/100] [Batch 200/870] [loss: 0.420642]\n",
      "[Epoch 9/100] [Batch 300/870] [loss: 0.177941]\n",
      "[Epoch 9/100] [Batch 400/870] [loss: 0.126002]\n",
      "[Epoch 9/100] [Batch 500/870] [loss: 0.054612]\n",
      "[Epoch 9/100] [Batch 600/870] [loss: 0.123758]\n",
      "[Epoch 9/100] [Batch 700/870] [loss: 0.028486]\n",
      "[Epoch 9/100] [Batch 800/870] [loss: 0.015053]\n",
      "-----[Epoch 9/100] [avg_train_loss: 0.000414]-----\n",
      "validation loss: 34.72938537597656\n",
      "validation loss: 21.833415985107422\n",
      "validation loss: 8.852167129516602\n",
      "-----[val_avg_loss 9.335493]-----\n",
      "EarlyStopping counter: 2 out of 40\n",
      "[Epoch 10/100] [Batch 0/870] [loss: 0.196388]\n",
      "[Epoch 10/100] [Batch 100/870] [loss: 0.089868]\n",
      "[Epoch 10/100] [Batch 200/870] [loss: 0.019580]\n",
      "[Epoch 10/100] [Batch 300/870] [loss: 0.032844]\n",
      "[Epoch 10/100] [Batch 400/870] [loss: 0.004775]\n",
      "[Epoch 10/100] [Batch 500/870] [loss: 0.051354]\n",
      "[Epoch 10/100] [Batch 600/870] [loss: 0.113266]\n",
      "[Epoch 10/100] [Batch 700/870] [loss: 0.002776]\n",
      "[Epoch 10/100] [Batch 800/870] [loss: 0.058565]\n",
      "-----[Epoch 10/100] [avg_train_loss: 0.001642]-----\n",
      "validation loss: 21.055923461914062\n",
      "validation loss: 13.719598770141602\n",
      "validation loss: 2.969180107116699\n",
      "-----[val_avg_loss 9.660100]-----\n",
      "EarlyStopping counter: 3 out of 40\n",
      "[Epoch 11/100] [Batch 0/870] [loss: 0.021174]\n",
      "[Epoch 11/100] [Batch 100/870] [loss: 0.139144]\n",
      "[Epoch 11/100] [Batch 200/870] [loss: 0.025714]\n",
      "[Epoch 11/100] [Batch 300/870] [loss: 0.038043]\n",
      "[Epoch 11/100] [Batch 400/870] [loss: 0.020208]\n",
      "[Epoch 11/100] [Batch 500/870] [loss: 0.036009]\n",
      "[Epoch 11/100] [Batch 600/870] [loss: 0.041770]\n",
      "[Epoch 11/100] [Batch 700/870] [loss: 0.083425]\n",
      "[Epoch 11/100] [Batch 800/870] [loss: 0.035272]\n",
      "-----[Epoch 11/100] [avg_train_loss: 0.004192]-----\n",
      "validation loss: 19.234386444091797\n",
      "validation loss: 7.346895694732666\n",
      "validation loss: 4.512702941894531\n",
      "-----[val_avg_loss 9.724151]-----\n",
      "EarlyStopping counter: 4 out of 40\n",
      "[Epoch 12/100] [Batch 0/870] [loss: 0.110910]\n",
      "[Epoch 12/100] [Batch 100/870] [loss: 0.113473]\n",
      "[Epoch 12/100] [Batch 200/870] [loss: 0.373794]\n",
      "[Epoch 12/100] [Batch 300/870] [loss: 0.052519]\n",
      "[Epoch 12/100] [Batch 400/870] [loss: 0.014649]\n",
      "[Epoch 12/100] [Batch 500/870] [loss: 0.341289]\n",
      "[Epoch 12/100] [Batch 600/870] [loss: 0.224236]\n",
      "[Epoch 12/100] [Batch 700/870] [loss: 0.001572]\n",
      "[Epoch 12/100] [Batch 800/870] [loss: 0.016824]\n",
      "-----[Epoch 12/100] [avg_train_loss: 0.000606]-----\n",
      "validation loss: 22.821380615234375\n",
      "validation loss: 0.06220942363142967\n",
      "validation loss: 20.21337127685547\n",
      "-----[val_avg_loss 10.110943]-----\n",
      "EarlyStopping counter: 5 out of 40\n",
      "[Epoch 13/100] [Batch 0/870] [loss: 0.023105]\n",
      "[Epoch 13/100] [Batch 100/870] [loss: 0.014479]\n",
      "[Epoch 13/100] [Batch 200/870] [loss: 0.117927]\n",
      "[Epoch 13/100] [Batch 300/870] [loss: 0.055397]\n",
      "[Epoch 13/100] [Batch 400/870] [loss: 1.419342]\n",
      "[Epoch 13/100] [Batch 500/870] [loss: 0.075947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/100] [Batch 600/870] [loss: 0.036212]\n",
      "[Epoch 13/100] [Batch 700/870] [loss: 0.002649]\n",
      "[Epoch 13/100] [Batch 800/870] [loss: 0.001798]\n",
      "-----[Epoch 13/100] [avg_train_loss: 0.193531]-----\n",
      "validation loss: 5.811218738555908\n",
      "validation loss: 15.76420783996582\n",
      "validation loss: 0.8315023183822632\n",
      "-----[val_avg_loss 9.907715]-----\n",
      "Validation loss decreased (1.272917 --> 0.831502).  Saving model ...\n",
      "[Epoch 14/100] [Batch 0/870] [loss: 0.062413]\n",
      "[Epoch 14/100] [Batch 100/870] [loss: 0.012028]\n",
      "[Epoch 14/100] [Batch 200/870] [loss: 0.629920]\n",
      "[Epoch 14/100] [Batch 300/870] [loss: 0.451897]\n",
      "[Epoch 14/100] [Batch 400/870] [loss: 0.017680]\n",
      "[Epoch 14/100] [Batch 500/870] [loss: 0.060402]\n",
      "[Epoch 14/100] [Batch 600/870] [loss: 0.142645]\n",
      "[Epoch 14/100] [Batch 700/870] [loss: 0.084459]\n",
      "[Epoch 14/100] [Batch 800/870] [loss: 0.005104]\n",
      "-----[Epoch 14/100] [avg_train_loss: 0.010890]-----\n",
      "validation loss: 29.83350944519043\n",
      "validation loss: 9.165514945983887\n",
      "validation loss: 9.665331840515137\n",
      "-----[val_avg_loss 10.358696]-----\n",
      "EarlyStopping counter: 1 out of 40\n",
      "[Epoch 15/100] [Batch 0/870] [loss: 0.094692]\n",
      "[Epoch 15/100] [Batch 100/870] [loss: 0.326935]\n",
      "[Epoch 15/100] [Batch 200/870] [loss: 0.112290]\n",
      "[Epoch 15/100] [Batch 300/870] [loss: 0.090008]\n",
      "[Epoch 15/100] [Batch 400/870] [loss: 0.055427]\n",
      "[Epoch 15/100] [Batch 500/870] [loss: 0.173095]\n",
      "[Epoch 15/100] [Batch 600/870] [loss: 0.266598]\n",
      "[Epoch 15/100] [Batch 700/870] [loss: 0.142696]\n",
      "[Epoch 15/100] [Batch 800/870] [loss: 0.283957]\n",
      "-----[Epoch 15/100] [avg_train_loss: 0.000973]-----\n",
      "validation loss: 10.71045207977295\n",
      "validation loss: 11.974809646606445\n",
      "validation loss: 5.460346221923828\n",
      "-----[val_avg_loss 10.293574]-----\n",
      "EarlyStopping counter: 2 out of 40\n",
      "[Epoch 16/100] [Batch 0/870] [loss: 0.113659]\n",
      "[Epoch 16/100] [Batch 100/870] [loss: 0.269919]\n",
      "[Epoch 16/100] [Batch 200/870] [loss: 0.095428]\n",
      "[Epoch 16/100] [Batch 300/870] [loss: 0.009928]\n",
      "[Epoch 16/100] [Batch 400/870] [loss: 0.041456]\n",
      "[Epoch 16/100] [Batch 500/870] [loss: 0.004477]\n",
      "[Epoch 16/100] [Batch 600/870] [loss: 0.000869]\n",
      "[Epoch 16/100] [Batch 700/870] [loss: 0.010265]\n",
      "[Epoch 16/100] [Batch 800/870] [loss: 0.333978]\n",
      "-----[Epoch 16/100] [avg_train_loss: 0.000155]-----\n",
      "validation loss: 30.476964950561523\n",
      "validation loss: 3.9480836391448975\n",
      "validation loss: 27.73657989501953\n",
      "-----[val_avg_loss 10.945260]-----\n",
      "EarlyStopping counter: 3 out of 40\n",
      "[Epoch 17/100] [Batch 0/870] [loss: 0.122227]\n",
      "[Epoch 17/100] [Batch 100/870] [loss: 0.023180]\n",
      "[Epoch 17/100] [Batch 200/870] [loss: 0.031475]\n",
      "[Epoch 17/100] [Batch 300/870] [loss: 0.625063]\n",
      "[Epoch 17/100] [Batch 400/870] [loss: 0.034988]\n",
      "[Epoch 17/100] [Batch 500/870] [loss: 0.024482]\n",
      "[Epoch 17/100] [Batch 600/870] [loss: 0.101573]\n",
      "[Epoch 17/100] [Batch 700/870] [loss: 0.028253]\n",
      "[Epoch 17/100] [Batch 800/870] [loss: 0.214626]\n",
      "-----[Epoch 17/100] [avg_train_loss: 0.000406]-----\n",
      "validation loss: 23.157691955566406\n",
      "validation loss: 29.502971649169922\n",
      "validation loss: 17.081098556518555\n",
      "-----[val_avg_loss 11.668907]-----\n",
      "EarlyStopping counter: 4 out of 40\n",
      "[Epoch 18/100] [Batch 0/870] [loss: 0.367956]\n",
      "[Epoch 18/100] [Batch 100/870] [loss: 0.012021]\n",
      "[Epoch 18/100] [Batch 200/870] [loss: 0.006050]\n",
      "[Epoch 18/100] [Batch 300/870] [loss: 0.331258]\n",
      "[Epoch 18/100] [Batch 400/870] [loss: 0.006295]\n",
      "[Epoch 18/100] [Batch 500/870] [loss: 0.030838]\n",
      "[Epoch 18/100] [Batch 600/870] [loss: 0.011531]\n",
      "[Epoch 18/100] [Batch 700/870] [loss: 0.249000]\n",
      "[Epoch 18/100] [Batch 800/870] [loss: 0.048637]\n",
      "-----[Epoch 18/100] [avg_train_loss: 0.001304]-----\n",
      "validation loss: 17.679149627685547\n",
      "validation loss: 1.0879242420196533\n",
      "validation loss: 5.9117608070373535\n",
      "-----[val_avg_loss 11.477650]-----\n",
      "EarlyStopping counter: 5 out of 40\n",
      "[Epoch 19/100] [Batch 0/870] [loss: 0.242395]\n",
      "[Epoch 19/100] [Batch 100/870] [loss: 0.099676]\n",
      "[Epoch 19/100] [Batch 200/870] [loss: 0.035019]\n",
      "[Epoch 19/100] [Batch 300/870] [loss: 0.050106]\n",
      "[Epoch 19/100] [Batch 400/870] [loss: 0.048770]\n",
      "[Epoch 19/100] [Batch 500/870] [loss: 0.039529]\n",
      "[Epoch 19/100] [Batch 600/870] [loss: 0.047791]\n",
      "[Epoch 19/100] [Batch 700/870] [loss: 0.008818]\n",
      "[Epoch 19/100] [Batch 800/870] [loss: 0.107246]\n",
      "-----[Epoch 19/100] [avg_train_loss: 0.001209]-----\n",
      "validation loss: 8.565746307373047\n",
      "validation loss: 6.419280052185059\n",
      "validation loss: 15.988848686218262\n",
      "-----[val_avg_loss 11.416964]-----\n",
      "EarlyStopping counter: 6 out of 40\n",
      "[Epoch 20/100] [Batch 0/870] [loss: 0.001695]\n",
      "[Epoch 20/100] [Batch 100/870] [loss: 0.328783]\n",
      "[Epoch 20/100] [Batch 200/870] [loss: 0.006949]\n",
      "[Epoch 20/100] [Batch 300/870] [loss: 0.150696]\n",
      "[Epoch 20/100] [Batch 400/870] [loss: 0.557585]\n",
      "[Epoch 20/100] [Batch 500/870] [loss: 0.001074]\n",
      "[Epoch 20/100] [Batch 600/870] [loss: 0.009092]\n",
      "[Epoch 20/100] [Batch 700/870] [loss: 0.076457]\n",
      "[Epoch 20/100] [Batch 800/870] [loss: 0.430763]\n",
      "-----[Epoch 20/100] [avg_train_loss: 0.377077]-----\n",
      "validation loss: 1.2429457902908325\n",
      "validation loss: 7.292422294616699\n",
      "validation loss: 4.9314961433410645\n",
      "-----[val_avg_loss 11.070564]-----\n",
      "EarlyStopping counter: 7 out of 40\n",
      "[Epoch 21/100] [Batch 0/870] [loss: 1.009219]\n",
      "[Epoch 21/100] [Batch 100/870] [loss: 0.108293]\n",
      "[Epoch 21/100] [Batch 200/870] [loss: 0.127610]\n",
      "[Epoch 21/100] [Batch 300/870] [loss: 0.023637]\n",
      "[Epoch 21/100] [Batch 400/870] [loss: 0.056423]\n",
      "[Epoch 21/100] [Batch 500/870] [loss: 0.000600]\n",
      "[Epoch 21/100] [Batch 600/870] [loss: 0.051956]\n",
      "[Epoch 21/100] [Batch 700/870] [loss: 0.071015]\n",
      "[Epoch 21/100] [Batch 800/870] [loss: 0.043140]\n",
      "-----[Epoch 21/100] [avg_train_loss: 0.010963]-----\n",
      "validation loss: 10.312397956848145\n",
      "validation loss: 18.095964431762695\n",
      "validation loss: 4.971121311187744\n",
      "-----[val_avg_loss 11.073227]-----\n",
      "EarlyStopping counter: 8 out of 40\n",
      "[Epoch 22/100] [Batch 0/870] [loss: 0.003028]\n",
      "[Epoch 22/100] [Batch 100/870] [loss: 0.093439]\n",
      "[Epoch 22/100] [Batch 200/870] [loss: 0.408274]\n",
      "[Epoch 22/100] [Batch 300/870] [loss: 0.007942]\n",
      "[Epoch 22/100] [Batch 400/870] [loss: 0.225730]\n",
      "[Epoch 22/100] [Batch 500/870] [loss: 0.056500]\n",
      "[Epoch 22/100] [Batch 600/870] [loss: 0.027985]\n",
      "[Epoch 22/100] [Batch 700/870] [loss: 0.008501]\n",
      "[Epoch 22/100] [Batch 800/870] [loss: 0.044351]\n",
      "-----[Epoch 22/100] [avg_train_loss: 0.000398]-----\n",
      "validation loss: 5.219250202178955\n",
      "validation loss: 21.70102310180664\n",
      "validation loss: 7.529504299163818\n",
      "-----[val_avg_loss 11.091865]-----\n",
      "EarlyStopping counter: 9 out of 40\n",
      "[Epoch 23/100] [Batch 0/870] [loss: 0.000612]\n",
      "[Epoch 23/100] [Batch 100/870] [loss: 0.165657]\n",
      "[Epoch 23/100] [Batch 200/870] [loss: 0.125177]\n",
      "[Epoch 23/100] [Batch 300/870] [loss: 0.404980]\n",
      "[Epoch 23/100] [Batch 400/870] [loss: 0.195775]\n",
      "[Epoch 23/100] [Batch 500/870] [loss: 0.150988]\n",
      "[Epoch 23/100] [Batch 600/870] [loss: 0.000262]\n",
      "[Epoch 23/100] [Batch 700/870] [loss: 0.231832]\n",
      "[Epoch 23/100] [Batch 800/870] [loss: 0.345489]\n",
      "-----[Epoch 23/100] [avg_train_loss: 0.101588]-----\n",
      "validation loss: 5.719510078430176\n",
      "validation loss: 12.110414505004883\n",
      "validation loss: 27.414417266845703\n",
      "-----[val_avg_loss 11.265325]-----\n",
      "EarlyStopping counter: 10 out of 40\n",
      "[Epoch 24/100] [Batch 0/870] [loss: 0.008295]\n",
      "[Epoch 24/100] [Batch 100/870] [loss: 0.058996]\n",
      "[Epoch 24/100] [Batch 200/870] [loss: 0.014967]\n",
      "[Epoch 24/100] [Batch 300/870] [loss: 0.026752]\n",
      "[Epoch 24/100] [Batch 400/870] [loss: 0.814159]\n",
      "[Epoch 24/100] [Batch 500/870] [loss: 0.137896]\n",
      "[Epoch 24/100] [Batch 600/870] [loss: 0.016415]\n",
      "[Epoch 24/100] [Batch 700/870] [loss: 0.000534]\n",
      "[Epoch 24/100] [Batch 800/870] [loss: 0.102261]\n",
      "-----[Epoch 24/100] [avg_train_loss: 0.174655]-----\n",
      "validation loss: 14.017692565917969\n",
      "validation loss: 0.06551109999418259\n",
      "validation loss: 0.3210804760456085\n",
      "-----[val_avg_loss 10.995996]-----\n",
      "Validation loss decreased (0.831502 --> 0.321080).  Saving model ...\n",
      "[Epoch 25/100] [Batch 0/870] [loss: 0.219415]\n",
      "[Epoch 25/100] [Batch 100/870] [loss: 0.174931]\n",
      "[Epoch 25/100] [Batch 200/870] [loss: 0.136995]\n",
      "[Epoch 25/100] [Batch 300/870] [loss: 0.446397]\n",
      "[Epoch 25/100] [Batch 400/870] [loss: 0.005618]\n",
      "[Epoch 25/100] [Batch 500/870] [loss: 0.117705]\n",
      "[Epoch 25/100] [Batch 600/870] [loss: 0.386625]\n",
      "[Epoch 25/100] [Batch 700/870] [loss: 0.493315]\n",
      "[Epoch 25/100] [Batch 800/870] [loss: 0.225770]\n",
      "-----[Epoch 25/100] [avg_train_loss: 0.626404]-----\n",
      "validation loss: 49.868900299072266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 45.08815002441406\n",
      "validation loss: 15.458662986755371\n",
      "-----[val_avg_loss 12.028366]-----\n",
      "EarlyStopping counter: 1 out of 40\n",
      "[Epoch 26/100] [Batch 0/870] [loss: 0.035109]\n",
      "[Epoch 26/100] [Batch 100/870] [loss: 0.003978]\n",
      "[Epoch 26/100] [Batch 200/870] [loss: 0.055177]\n",
      "[Epoch 26/100] [Batch 300/870] [loss: 0.008137]\n",
      "[Epoch 26/100] [Batch 400/870] [loss: 0.006588]\n",
      "[Epoch 26/100] [Batch 500/870] [loss: 0.033039]\n",
      "[Epoch 26/100] [Batch 600/870] [loss: 0.116938]\n",
      "[Epoch 26/100] [Batch 700/870] [loss: 0.032737]\n",
      "[Epoch 26/100] [Batch 800/870] [loss: 0.012317]\n",
      "-----[Epoch 26/100] [avg_train_loss: 0.032919]-----\n",
      "validation loss: 11.866551399230957\n",
      "validation loss: 4.125335216522217\n",
      "validation loss: 0.015078019350767136\n",
      "-----[val_avg_loss 11.770954]-----\n",
      "Validation loss decreased (0.321080 --> 0.015078).  Saving model ...\n",
      "[Epoch 27/100] [Batch 0/870] [loss: 0.052498]\n",
      "[Epoch 27/100] [Batch 100/870] [loss: 0.044015]\n",
      "[Epoch 27/100] [Batch 200/870] [loss: 0.022291]\n",
      "[Epoch 27/100] [Batch 300/870] [loss: 0.001566]\n",
      "[Epoch 27/100] [Batch 400/870] [loss: 0.509554]\n",
      "[Epoch 27/100] [Batch 500/870] [loss: 0.017186]\n",
      "[Epoch 27/100] [Batch 600/870] [loss: 0.130862]\n",
      "[Epoch 27/100] [Batch 700/870] [loss: 0.010676]\n",
      "[Epoch 27/100] [Batch 800/870] [loss: 0.022546]\n",
      "-----[Epoch 27/100] [avg_train_loss: 0.049653]-----\n",
      "validation loss: 10.355875968933105\n",
      "validation loss: 13.163772583007812\n",
      "validation loss: 2.9511795043945312\n",
      "-----[val_avg_loss 11.661793]-----\n",
      "EarlyStopping counter: 1 out of 40\n",
      "[Epoch 28/100] [Batch 0/870] [loss: 0.797269]\n",
      "[Epoch 28/100] [Batch 100/870] [loss: 0.217981]\n",
      "[Epoch 28/100] [Batch 200/870] [loss: 0.060502]\n",
      "[Epoch 28/100] [Batch 300/870] [loss: 0.049524]\n",
      "[Epoch 28/100] [Batch 400/870] [loss: 0.005705]\n",
      "[Epoch 28/100] [Batch 500/870] [loss: 0.002583]\n",
      "[Epoch 28/100] [Batch 600/870] [loss: 0.027695]\n",
      "[Epoch 28/100] [Batch 700/870] [loss: 0.004182]\n",
      "[Epoch 28/100] [Batch 800/870] [loss: 0.042740]\n",
      "-----[Epoch 28/100] [avg_train_loss: 0.002970]-----\n",
      "validation loss: 3.2060484886169434\n",
      "validation loss: 14.881979942321777\n",
      "validation loss: 14.879998207092285\n",
      "-----[val_avg_loss 11.637777]-----\n",
      "EarlyStopping counter: 2 out of 40\n",
      "[Epoch 29/100] [Batch 0/870] [loss: 0.061196]\n",
      "[Epoch 29/100] [Batch 100/870] [loss: 0.002782]\n",
      "[Epoch 29/100] [Batch 200/870] [loss: 0.363130]\n",
      "[Epoch 29/100] [Batch 300/870] [loss: 0.018733]\n",
      "[Epoch 29/100] [Batch 400/870] [loss: 0.004640]\n",
      "[Epoch 29/100] [Batch 500/870] [loss: 0.081076]\n",
      "[Epoch 29/100] [Batch 600/870] [loss: 0.008677]\n",
      "[Epoch 29/100] [Batch 700/870] [loss: 0.191977]\n",
      "[Epoch 29/100] [Batch 800/870] [loss: 0.008636]\n",
      "-----[Epoch 29/100] [avg_train_loss: 0.002023]-----\n",
      "validation loss: 19.619253158569336\n",
      "validation loss: 15.515645027160645\n",
      "validation loss: 4.201354503631592\n",
      "-----[val_avg_loss 11.688615]-----\n",
      "EarlyStopping counter: 3 out of 40\n",
      "[Epoch 30/100] [Batch 0/870] [loss: 0.020668]\n",
      "[Epoch 30/100] [Batch 100/870] [loss: 0.001938]\n",
      "[Epoch 30/100] [Batch 200/870] [loss: 0.097670]\n",
      "[Epoch 30/100] [Batch 300/870] [loss: 0.527656]\n",
      "[Epoch 30/100] [Batch 400/870] [loss: 0.004646]\n",
      "[Epoch 30/100] [Batch 500/870] [loss: 0.099323]\n",
      "[Epoch 30/100] [Batch 600/870] [loss: 0.029354]\n",
      "[Epoch 30/100] [Batch 700/870] [loss: 0.056466]\n",
      "[Epoch 30/100] [Batch 800/870] [loss: 0.216109]\n",
      "-----[Epoch 30/100] [avg_train_loss: 0.002945]-----\n",
      "validation loss: 8.901569366455078\n",
      "validation loss: 28.8405818939209\n",
      "validation loss: 6.2548508644104\n",
      "-----[val_avg_loss 11.787850]-----\n",
      "EarlyStopping counter: 4 out of 40\n",
      "[Epoch 31/100] [Batch 0/870] [loss: 0.006214]\n",
      "[Epoch 31/100] [Batch 100/870] [loss: 0.177427]\n",
      "[Epoch 31/100] [Batch 200/870] [loss: 0.413568]\n",
      "[Epoch 31/100] [Batch 300/870] [loss: 0.017893]\n",
      "[Epoch 31/100] [Batch 400/870] [loss: 0.027908]\n",
      "[Epoch 31/100] [Batch 500/870] [loss: 0.328145]\n",
      "[Epoch 31/100] [Batch 600/870] [loss: 0.023982]\n",
      "[Epoch 31/100] [Batch 700/870] [loss: 0.008981]\n",
      "[Epoch 31/100] [Batch 800/870] [loss: 0.021236]\n",
      "-----[Epoch 31/100] [avg_train_loss: 0.118920]-----\n",
      "validation loss: 15.026829719543457\n",
      "validation loss: 17.95858383178711\n",
      "validation loss: 4.619892120361328\n",
      "-----[val_avg_loss 11.811955]-----\n",
      "EarlyStopping counter: 5 out of 40\n",
      "[Epoch 32/100] [Batch 0/870] [loss: 0.174185]\n",
      "[Epoch 32/100] [Batch 100/870] [loss: 0.058096]\n",
      "[Epoch 32/100] [Batch 200/870] [loss: 0.056830]\n",
      "[Epoch 32/100] [Batch 300/870] [loss: 0.014067]\n",
      "[Epoch 32/100] [Batch 400/870] [loss: 0.003720]\n",
      "[Epoch 32/100] [Batch 500/870] [loss: 0.000137]\n",
      "[Epoch 32/100] [Batch 600/870] [loss: 0.022175]\n",
      "[Epoch 32/100] [Batch 700/870] [loss: 0.007173]\n",
      "[Epoch 32/100] [Batch 800/870] [loss: 0.005934]\n",
      "-----[Epoch 32/100] [avg_train_loss: 0.001552]-----\n",
      "validation loss: 2.1228621006011963\n",
      "validation loss: 30.968456268310547\n",
      "validation loss: 28.983318328857422\n",
      "-----[val_avg_loss 12.089442]-----\n",
      "EarlyStopping counter: 6 out of 40\n",
      "[Epoch 33/100] [Batch 0/870] [loss: 0.004150]\n",
      "[Epoch 33/100] [Batch 100/870] [loss: 0.424486]\n",
      "[Epoch 33/100] [Batch 200/870] [loss: 0.001765]\n",
      "[Epoch 33/100] [Batch 300/870] [loss: 0.303928]\n",
      "[Epoch 33/100] [Batch 400/870] [loss: 0.001409]\n",
      "[Epoch 33/100] [Batch 500/870] [loss: 0.313450]\n",
      "[Epoch 33/100] [Batch 600/870] [loss: 0.009680]\n",
      "[Epoch 33/100] [Batch 700/870] [loss: 0.004490]\n",
      "[Epoch 33/100] [Batch 800/870] [loss: 0.026052]\n",
      "-----[Epoch 33/100] [avg_train_loss: 0.000411]-----\n",
      "validation loss: 11.752294540405273\n",
      "validation loss: 12.243020057678223\n",
      "validation loss: 25.92767333984375\n",
      "-----[val_avg_loss 12.227368]-----\n",
      "EarlyStopping counter: 7 out of 40\n",
      "[Epoch 34/100] [Batch 0/870] [loss: 0.071179]\n",
      "[Epoch 34/100] [Batch 100/870] [loss: 0.429344]\n",
      "[Epoch 34/100] [Batch 200/870] [loss: 0.066540]\n",
      "[Epoch 34/100] [Batch 300/870] [loss: 0.061576]\n",
      "[Epoch 34/100] [Batch 400/870] [loss: 0.061636]\n",
      "[Epoch 34/100] [Batch 500/870] [loss: 0.051703]\n",
      "[Epoch 34/100] [Batch 600/870] [loss: 0.002839]\n",
      "[Epoch 34/100] [Batch 700/870] [loss: 0.002163]\n",
      "[Epoch 34/100] [Batch 800/870] [loss: 0.004913]\n",
      "-----[Epoch 34/100] [avg_train_loss: 0.301436]-----\n",
      "validation loss: 0.6867913007736206\n",
      "validation loss: 0.05951166898012161\n",
      "validation loss: 6.62457275390625\n",
      "-----[val_avg_loss 11.940003]-----\n",
      "EarlyStopping counter: 8 out of 40\n",
      "[Epoch 35/100] [Batch 0/870] [loss: 0.315195]\n",
      "[Epoch 35/100] [Batch 100/870] [loss: 0.032675]\n",
      "[Epoch 35/100] [Batch 200/870] [loss: 0.008130]\n",
      "[Epoch 35/100] [Batch 300/870] [loss: 0.252184]\n",
      "[Epoch 35/100] [Batch 400/870] [loss: 0.014529]\n",
      "[Epoch 35/100] [Batch 500/870] [loss: 0.053555]\n",
      "[Epoch 35/100] [Batch 600/870] [loss: 0.014590]\n",
      "[Epoch 35/100] [Batch 700/870] [loss: 0.036248]\n",
      "[Epoch 35/100] [Batch 800/870] [loss: 0.376433]\n",
      "-----[Epoch 35/100] [avg_train_loss: 0.005398]-----\n",
      "validation loss: 22.11262321472168\n",
      "validation loss: 2.425172805786133\n",
      "validation loss: 1.4569662809371948\n",
      "-----[val_avg_loss 11.846429]-----\n",
      "EarlyStopping counter: 9 out of 40\n",
      "[Epoch 36/100] [Batch 0/870] [loss: 0.036126]\n",
      "[Epoch 36/100] [Batch 100/870] [loss: 0.004713]\n",
      "[Epoch 36/100] [Batch 200/870] [loss: 0.031567]\n",
      "[Epoch 36/100] [Batch 300/870] [loss: 0.090094]\n",
      "[Epoch 36/100] [Batch 400/870] [loss: 0.499811]\n",
      "[Epoch 36/100] [Batch 500/870] [loss: 0.039945]\n",
      "[Epoch 36/100] [Batch 600/870] [loss: 0.128801]\n",
      "[Epoch 36/100] [Batch 700/870] [loss: 0.040787]\n",
      "[Epoch 36/100] [Batch 800/870] [loss: 0.008795]\n",
      "-----[Epoch 36/100] [avg_train_loss: 0.026718]-----\n",
      "validation loss: 18.472646713256836\n",
      "validation loss: 16.309980392456055\n",
      "validation loss: 2.375981330871582\n",
      "-----[val_avg_loss 11.861423]-----\n",
      "EarlyStopping counter: 10 out of 40\n",
      "[Epoch 37/100] [Batch 0/870] [loss: 0.049544]\n",
      "[Epoch 37/100] [Batch 100/870] [loss: 0.336886]\n",
      "[Epoch 37/100] [Batch 200/870] [loss: 0.128382]\n",
      "[Epoch 37/100] [Batch 300/870] [loss: 0.086428]\n",
      "[Epoch 37/100] [Batch 400/870] [loss: 0.155474]\n",
      "[Epoch 37/100] [Batch 500/870] [loss: 0.058239]\n",
      "[Epoch 37/100] [Batch 600/870] [loss: 0.003089]\n",
      "[Epoch 37/100] [Batch 700/870] [loss: 0.000397]\n",
      "[Epoch 37/100] [Batch 800/870] [loss: 0.084490]\n",
      "-----[Epoch 37/100] [avg_train_loss: 0.003029]-----\n",
      "validation loss: 28.031238555908203\n",
      "validation loss: 9.735807418823242\n",
      "validation loss: 2.8038296699523926\n",
      "-----[val_avg_loss 11.906347]-----\n",
      "EarlyStopping counter: 11 out of 40\n",
      "[Epoch 38/100] [Batch 0/870] [loss: 0.253494]\n",
      "[Epoch 38/100] [Batch 100/870] [loss: 0.004392]\n",
      "[Epoch 38/100] [Batch 200/870] [loss: 0.012358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/100] [Batch 300/870] [loss: 0.010182]\n",
      "[Epoch 38/100] [Batch 400/870] [loss: 0.035171]\n",
      "[Epoch 38/100] [Batch 500/870] [loss: 0.196857]\n",
      "[Epoch 38/100] [Batch 600/870] [loss: 0.074751]\n",
      "[Epoch 38/100] [Batch 700/870] [loss: 0.731541]\n",
      "[Epoch 38/100] [Batch 800/870] [loss: 0.320486]\n",
      "-----[Epoch 38/100] [avg_train_loss: 0.008586]-----\n",
      "validation loss: 27.58959197998047\n",
      "validation loss: 3.88928484916687\n",
      "validation loss: 11.005369186401367\n",
      "-----[val_avg_loss 11.965691]-----\n",
      "EarlyStopping counter: 12 out of 40\n",
      "[Epoch 39/100] [Batch 0/870] [loss: 0.033317]\n",
      "[Epoch 39/100] [Batch 100/870] [loss: 0.001131]\n",
      "[Epoch 39/100] [Batch 200/870] [loss: 0.002550]\n",
      "[Epoch 39/100] [Batch 300/870] [loss: 0.152395]\n",
      "[Epoch 39/100] [Batch 400/870] [loss: 0.241439]\n",
      "[Epoch 39/100] [Batch 500/870] [loss: 0.003025]\n",
      "[Epoch 39/100] [Batch 600/870] [loss: 0.009264]\n",
      "[Epoch 39/100] [Batch 700/870] [loss: 0.001533]\n",
      "[Epoch 39/100] [Batch 800/870] [loss: 0.003911]\n",
      "-----[Epoch 39/100] [avg_train_loss: 0.003324]-----\n",
      "validation loss: 12.150694847106934\n",
      "validation loss: 14.864253044128418\n",
      "validation loss: 16.7156982421875\n",
      "-----[val_avg_loss 12.032645]-----\n",
      "EarlyStopping counter: 13 out of 40\n",
      "[Epoch 40/100] [Batch 0/870] [loss: 0.061500]\n",
      "[Epoch 40/100] [Batch 100/870] [loss: 0.003356]\n",
      "[Epoch 40/100] [Batch 200/870] [loss: 0.003968]\n",
      "[Epoch 40/100] [Batch 300/870] [loss: 0.010000]\n",
      "[Epoch 40/100] [Batch 400/870] [loss: 0.012569]\n",
      "[Epoch 40/100] [Batch 500/870] [loss: 0.008218]\n",
      "[Epoch 40/100] [Batch 600/870] [loss: 0.003843]\n",
      "[Epoch 40/100] [Batch 700/870] [loss: 0.364694]\n",
      "[Epoch 40/100] [Batch 800/870] [loss: 0.013770]\n",
      "-----[Epoch 40/100] [avg_train_loss: 0.026489]-----\n",
      "validation loss: 19.984146118164062\n",
      "validation loss: 0.23774243891239166\n",
      "validation loss: 19.391651153564453\n",
      "-----[val_avg_loss 12.061941]-----\n",
      "EarlyStopping counter: 14 out of 40\n",
      "[Epoch 41/100] [Batch 0/870] [loss: 0.049392]\n",
      "[Epoch 41/100] [Batch 100/870] [loss: 0.001593]\n",
      "[Epoch 41/100] [Batch 200/870] [loss: 0.013037]\n",
      "[Epoch 41/100] [Batch 300/870] [loss: 0.025320]\n",
      "[Epoch 41/100] [Batch 400/870] [loss: 0.030375]\n",
      "[Epoch 41/100] [Batch 500/870] [loss: 0.006850]\n",
      "[Epoch 41/100] [Batch 600/870] [loss: 0.167126]\n",
      "[Epoch 41/100] [Batch 700/870] [loss: 0.012947]\n",
      "[Epoch 41/100] [Batch 800/870] [loss: 0.016429]\n",
      "-----[Epoch 41/100] [avg_train_loss: 0.004254]-----\n",
      "validation loss: 9.314071655273438\n",
      "validation loss: 18.136157989501953\n",
      "validation loss: 3.378471851348877\n",
      "-----[val_avg_loss 12.018388]-----\n",
      "EarlyStopping counter: 15 out of 40\n",
      "[Epoch 42/100] [Batch 0/870] [loss: 0.065402]\n",
      "[Epoch 42/100] [Batch 100/870] [loss: 0.129829]\n",
      "[Epoch 42/100] [Batch 200/870] [loss: 0.077562]\n",
      "[Epoch 42/100] [Batch 300/870] [loss: 0.002186]\n",
      "[Epoch 42/100] [Batch 400/870] [loss: 0.118928]\n",
      "[Epoch 42/100] [Batch 500/870] [loss: 0.011466]\n",
      "[Epoch 42/100] [Batch 600/870] [loss: 0.297550]\n",
      "[Epoch 42/100] [Batch 700/870] [loss: 0.028684]\n",
      "[Epoch 42/100] [Batch 800/870] [loss: 0.028687]\n",
      "-----[Epoch 42/100] [avg_train_loss: 0.677208]-----\n",
      "validation loss: 63.63249206542969\n",
      "validation loss: 21.837276458740234\n",
      "validation loss: 32.80962371826172\n",
      "-----[val_avg_loss 12.670961]-----\n",
      "EarlyStopping counter: 16 out of 40\n",
      "[Epoch 43/100] [Batch 0/870] [loss: 0.385431]\n",
      "[Epoch 43/100] [Batch 100/870] [loss: 0.610753]\n",
      "[Epoch 43/100] [Batch 200/870] [loss: 0.051834]\n",
      "[Epoch 43/100] [Batch 300/870] [loss: 0.026212]\n",
      "[Epoch 43/100] [Batch 400/870] [loss: 0.006710]\n",
      "[Epoch 43/100] [Batch 500/870] [loss: 0.004304]\n",
      "[Epoch 43/100] [Batch 600/870] [loss: 0.000188]\n",
      "[Epoch 43/100] [Batch 700/870] [loss: 0.007812]\n",
      "[Epoch 43/100] [Batch 800/870] [loss: 0.008104]\n",
      "-----[Epoch 43/100] [avg_train_loss: 0.387712]-----\n",
      "validation loss: 18.40574073791504\n",
      "validation loss: 38.379398345947266\n",
      "validation loss: 16.06558609008789\n",
      "-----[val_avg_loss 12.941022]-----\n",
      "EarlyStopping counter: 17 out of 40\n",
      "[Epoch 44/100] [Batch 0/870] [loss: 0.199484]\n",
      "[Epoch 44/100] [Batch 100/870] [loss: 0.079191]\n",
      "[Epoch 44/100] [Batch 200/870] [loss: 0.282940]\n",
      "[Epoch 44/100] [Batch 300/870] [loss: 0.007703]\n",
      "[Epoch 44/100] [Batch 400/870] [loss: 0.529443]\n",
      "[Epoch 44/100] [Batch 500/870] [loss: 0.007187]\n",
      "[Epoch 44/100] [Batch 600/870] [loss: 0.136925]\n",
      "[Epoch 44/100] [Batch 700/870] [loss: 0.142336]\n",
      "[Epoch 44/100] [Batch 800/870] [loss: 0.000906]\n",
      "-----[Epoch 44/100] [avg_train_loss: 0.000435]-----\n",
      "validation loss: 12.585671424865723\n",
      "validation loss: 0.8551895022392273\n",
      "validation loss: 15.218587875366211\n",
      "-----[val_avg_loss 12.864025]-----\n",
      "EarlyStopping counter: 18 out of 40\n",
      "[Epoch 45/100] [Batch 0/870] [loss: 0.008641]\n",
      "[Epoch 45/100] [Batch 100/870] [loss: 0.002100]\n",
      "[Epoch 45/100] [Batch 200/870] [loss: 0.010292]\n",
      "[Epoch 45/100] [Batch 300/870] [loss: 0.062139]\n",
      "[Epoch 45/100] [Batch 400/870] [loss: 0.000717]\n",
      "[Epoch 45/100] [Batch 500/870] [loss: 0.009645]\n",
      "[Epoch 45/100] [Batch 600/870] [loss: 0.061337]\n",
      "[Epoch 45/100] [Batch 700/870] [loss: 0.019575]\n",
      "[Epoch 45/100] [Batch 800/870] [loss: 0.006575]\n",
      "-----[Epoch 45/100] [avg_train_loss: 0.000171]-----\n",
      "validation loss: 20.28554344177246\n",
      "validation loss: 5.746301174163818\n",
      "validation loss: 2.2508325576782227\n",
      "-----[val_avg_loss 12.787659]-----\n",
      "EarlyStopping counter: 19 out of 40\n",
      "[Epoch 46/100] [Batch 0/870] [loss: 0.164634]\n",
      "[Epoch 46/100] [Batch 100/870] [loss: 0.027797]\n",
      "[Epoch 46/100] [Batch 200/870] [loss: 0.001327]\n",
      "[Epoch 46/100] [Batch 300/870] [loss: 0.005897]\n",
      "[Epoch 46/100] [Batch 400/870] [loss: 0.019019]\n",
      "[Epoch 46/100] [Batch 500/870] [loss: 0.000370]\n",
      "[Epoch 46/100] [Batch 600/870] [loss: 0.021865]\n",
      "[Epoch 46/100] [Batch 700/870] [loss: 0.003868]\n",
      "[Epoch 46/100] [Batch 800/870] [loss: 0.246478]\n",
      "-----[Epoch 46/100] [avg_train_loss: 0.001294]-----\n",
      "validation loss: 22.457054138183594\n",
      "validation loss: 7.7084245681762695\n",
      "validation loss: 0.00046822911826893687\n",
      "-----[val_avg_loss 12.728260]-----\n",
      "Validation loss decreased (0.015078 --> 0.000468).  Saving model ...\n",
      "[Epoch 47/100] [Batch 0/870] [loss: 0.004014]\n",
      "[Epoch 47/100] [Batch 100/870] [loss: 0.003944]\n",
      "[Epoch 47/100] [Batch 200/870] [loss: 0.006977]\n",
      "[Epoch 47/100] [Batch 300/870] [loss: 0.021642]\n",
      "[Epoch 47/100] [Batch 400/870] [loss: 0.021117]\n",
      "[Epoch 47/100] [Batch 500/870] [loss: 0.005003]\n",
      "[Epoch 47/100] [Batch 600/870] [loss: 0.044494]\n",
      "[Epoch 47/100] [Batch 700/870] [loss: 0.009961]\n",
      "[Epoch 47/100] [Batch 800/870] [loss: 0.000233]\n",
      "-----[Epoch 47/100] [avg_train_loss: 0.007161]-----\n",
      "validation loss: 21.168006896972656\n",
      "validation loss: 2.3712992668151855\n",
      "validation loss: 6.947876453399658\n",
      "-----[val_avg_loss 12.673667]-----\n",
      "EarlyStopping counter: 1 out of 40\n",
      "[Epoch 48/100] [Batch 0/870] [loss: 0.009009]\n",
      "[Epoch 48/100] [Batch 100/870] [loss: 0.000800]\n",
      "[Epoch 48/100] [Batch 200/870] [loss: 0.019665]\n",
      "[Epoch 48/100] [Batch 300/870] [loss: 0.004127]\n",
      "[Epoch 48/100] [Batch 400/870] [loss: 0.000678]\n",
      "[Epoch 48/100] [Batch 500/870] [loss: 0.000257]\n",
      "[Epoch 48/100] [Batch 600/870] [loss: 0.866819]\n",
      "[Epoch 48/100] [Batch 700/870] [loss: 0.341214]\n",
      "[Epoch 48/100] [Batch 800/870] [loss: 0.078292]\n",
      "-----[Epoch 48/100] [avg_train_loss: 0.007889]-----\n",
      "validation loss: 3.683422088623047\n",
      "validation loss: 0.3604394197463989\n",
      "validation loss: 12.62190055847168\n",
      "-----[val_avg_loss 12.525367]-----\n",
      "EarlyStopping counter: 2 out of 40\n",
      "[Epoch 49/100] [Batch 0/870] [loss: 0.029276]\n",
      "[Epoch 49/100] [Batch 100/870] [loss: 0.001157]\n",
      "[Epoch 49/100] [Batch 200/870] [loss: 0.003695]\n",
      "[Epoch 49/100] [Batch 300/870] [loss: 0.219438]\n",
      "[Epoch 49/100] [Batch 400/870] [loss: 0.086586]\n",
      "[Epoch 49/100] [Batch 500/870] [loss: 0.001827]\n",
      "[Epoch 49/100] [Batch 600/870] [loss: 0.189122]\n",
      "[Epoch 49/100] [Batch 700/870] [loss: 0.020054]\n",
      "[Epoch 49/100] [Batch 800/870] [loss: 0.267562]\n",
      "-----[Epoch 49/100] [avg_train_loss: 0.000330]-----\n",
      "validation loss: 19.32814598083496\n",
      "validation loss: 2.9008703231811523\n",
      "validation loss: 9.26573371887207\n",
      "-----[val_avg_loss 12.483997]-----\n",
      "EarlyStopping counter: 3 out of 40\n",
      "[Epoch 50/100] [Batch 0/870] [loss: 0.009085]\n",
      "[Epoch 50/100] [Batch 100/870] [loss: 0.186996]\n",
      "[Epoch 50/100] [Batch 200/870] [loss: 0.001765]\n",
      "[Epoch 50/100] [Batch 300/870] [loss: 0.025475]\n",
      "[Epoch 50/100] [Batch 400/870] [loss: 0.000878]\n",
      "[Epoch 50/100] [Batch 500/870] [loss: 0.000290]\n",
      "[Epoch 50/100] [Batch 600/870] [loss: 0.010980]\n",
      "[Epoch 50/100] [Batch 700/870] [loss: 0.019010]\n",
      "[Epoch 50/100] [Batch 800/870] [loss: 0.084163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----[Epoch 50/100] [avg_train_loss: 0.015511]-----\n",
      "validation loss: 1.4168199300765991\n",
      "validation loss: 37.599876403808594\n",
      "validation loss: 9.99209976196289\n",
      "-----[val_avg_loss 12.561042]-----\n",
      "EarlyStopping counter: 4 out of 40\n",
      "[Epoch 51/100] [Batch 0/870] [loss: 0.005636]\n",
      "[Epoch 51/100] [Batch 100/870] [loss: 0.010855]\n",
      "[Epoch 51/100] [Batch 200/870] [loss: 0.022190]\n",
      "[Epoch 51/100] [Batch 300/870] [loss: 0.007695]\n",
      "[Epoch 51/100] [Batch 400/870] [loss: 0.001621]\n",
      "[Epoch 51/100] [Batch 500/870] [loss: 0.038868]\n",
      "[Epoch 51/100] [Batch 600/870] [loss: 0.005220]\n",
      "[Epoch 51/100] [Batch 700/870] [loss: 0.032123]\n",
      "[Epoch 51/100] [Batch 800/870] [loss: 0.000409]\n",
      "-----[Epoch 51/100] [avg_train_loss: 0.119576]-----\n",
      "validation loss: 0.7974138259887695\n",
      "validation loss: 14.572258949279785\n",
      "validation loss: 2.673143148422241\n",
      "-----[val_avg_loss 12.432674]-----\n",
      "EarlyStopping counter: 5 out of 40\n",
      "[Epoch 52/100] [Batch 0/870] [loss: 0.419226]\n",
      "[Epoch 52/100] [Batch 100/870] [loss: 0.000661]\n",
      "[Epoch 52/100] [Batch 200/870] [loss: 0.040377]\n",
      "[Epoch 52/100] [Batch 300/870] [loss: 0.000537]\n",
      "[Epoch 52/100] [Batch 400/870] [loss: 0.017247]\n",
      "[Epoch 52/100] [Batch 500/870] [loss: 0.063880]\n",
      "[Epoch 52/100] [Batch 600/870] [loss: 0.218353]\n",
      "[Epoch 52/100] [Batch 700/870] [loss: 0.266747]\n",
      "[Epoch 52/100] [Batch 800/870] [loss: 0.010117]\n",
      "-----[Epoch 52/100] [avg_train_loss: 0.000094]-----\n",
      "validation loss: 9.126203536987305\n",
      "validation loss: 11.407600402832031\n",
      "validation loss: 20.836294174194336\n",
      "-----[val_avg_loss 12.458777]-----\n",
      "EarlyStopping counter: 6 out of 40\n",
      "[Epoch 53/100] [Batch 0/870] [loss: 0.016478]\n",
      "[Epoch 53/100] [Batch 100/870] [loss: 0.036647]\n",
      "[Epoch 53/100] [Batch 200/870] [loss: 0.032781]\n",
      "[Epoch 53/100] [Batch 300/870] [loss: 0.005621]\n",
      "[Epoch 53/100] [Batch 400/870] [loss: 0.030029]\n",
      "[Epoch 53/100] [Batch 500/870] [loss: 0.086447]\n",
      "[Epoch 53/100] [Batch 600/870] [loss: 0.168414]\n",
      "[Epoch 53/100] [Batch 700/870] [loss: 0.003233]\n",
      "[Epoch 53/100] [Batch 800/870] [loss: 0.060510]\n",
      "-----[Epoch 53/100] [avg_train_loss: 0.024837]-----\n",
      "validation loss: 10.208271980285645\n",
      "validation loss: 9.955509185791016\n",
      "validation loss: 21.078088760375977\n",
      "-----[val_avg_loss 12.483089]-----\n",
      "EarlyStopping counter: 7 out of 40\n",
      "[Epoch 54/100] [Batch 0/870] [loss: 0.000876]\n",
      "[Epoch 54/100] [Batch 100/870] [loss: 0.004698]\n",
      "[Epoch 54/100] [Batch 200/870] [loss: 0.019566]\n",
      "[Epoch 54/100] [Batch 300/870] [loss: 0.105834]\n",
      "[Epoch 54/100] [Batch 400/870] [loss: 0.031817]\n",
      "[Epoch 54/100] [Batch 500/870] [loss: 0.001059]\n",
      "[Epoch 54/100] [Batch 600/870] [loss: 0.002912]\n",
      "[Epoch 54/100] [Batch 700/870] [loss: 0.134822]\n",
      "[Epoch 54/100] [Batch 800/870] [loss: 0.111454]\n",
      "-----[Epoch 54/100] [avg_train_loss: 0.000937]-----\n",
      "validation loss: 12.382735252380371\n",
      "validation loss: 38.57223129272461\n",
      "validation loss: 6.158275127410889\n",
      "-----[val_avg_loss 12.604471]-----\n",
      "EarlyStopping counter: 8 out of 40\n",
      "[Epoch 55/100] [Batch 0/870] [loss: 0.027603]\n",
      "[Epoch 55/100] [Batch 100/870] [loss: 0.013100]\n",
      "[Epoch 55/100] [Batch 200/870] [loss: 0.029931]\n",
      "[Epoch 55/100] [Batch 300/870] [loss: 0.005300]\n",
      "[Epoch 55/100] [Batch 400/870] [loss: 0.000568]\n",
      "[Epoch 55/100] [Batch 500/870] [loss: 0.002646]\n",
      "[Epoch 55/100] [Batch 600/870] [loss: 0.000394]\n",
      "[Epoch 55/100] [Batch 700/870] [loss: 0.001117]\n",
      "[Epoch 55/100] [Batch 800/870] [loss: 0.002136]\n",
      "-----[Epoch 55/100] [avg_train_loss: 0.055047]-----\n",
      "validation loss: 27.423389434814453\n",
      "validation loss: 7.7474141120910645\n",
      "validation loss: 10.869258880615234\n",
      "-----[val_avg_loss 12.654330]-----\n",
      "EarlyStopping counter: 9 out of 40\n",
      "[Epoch 56/100] [Batch 0/870] [loss: 0.004631]\n",
      "[Epoch 56/100] [Batch 100/870] [loss: 0.010216]\n",
      "[Epoch 56/100] [Batch 200/870] [loss: 0.004022]\n",
      "[Epoch 56/100] [Batch 300/870] [loss: 0.013905]\n",
      "[Epoch 56/100] [Batch 400/870] [loss: 0.000850]\n",
      "[Epoch 56/100] [Batch 500/870] [loss: 0.067194]\n",
      "[Epoch 56/100] [Batch 600/870] [loss: 0.267340]\n",
      "[Epoch 56/100] [Batch 700/870] [loss: 0.025536]\n",
      "[Epoch 56/100] [Batch 800/870] [loss: 0.001065]\n",
      "-----[Epoch 56/100] [avg_train_loss: 0.000133]-----\n",
      "validation loss: 0.11319498717784882\n",
      "validation loss: 16.29277992248535\n",
      "validation loss: 4.069681167602539\n",
      "-----[val_avg_loss 12.550239]-----\n",
      "EarlyStopping counter: 10 out of 40\n",
      "[Epoch 57/100] [Batch 0/870] [loss: 0.034758]\n",
      "[Epoch 57/100] [Batch 100/870] [loss: 0.011566]\n",
      "[Epoch 57/100] [Batch 200/870] [loss: 0.173967]\n",
      "[Epoch 57/100] [Batch 300/870] [loss: 0.068532]\n",
      "[Epoch 57/100] [Batch 400/870] [loss: 0.008256]\n",
      "[Epoch 57/100] [Batch 500/870] [loss: 0.003918]\n",
      "[Epoch 57/100] [Batch 600/870] [loss: 0.060331]\n",
      "[Epoch 57/100] [Batch 700/870] [loss: 0.004886]\n",
      "[Epoch 57/100] [Batch 800/870] [loss: 0.273317]\n",
      "-----[Epoch 57/100] [avg_train_loss: 0.000013]-----\n",
      "validation loss: 28.387004852294922\n",
      "validation loss: 16.750158309936523\n",
      "validation loss: 9.729670524597168\n",
      "-----[val_avg_loss 12.650918]-----\n",
      "EarlyStopping counter: 11 out of 40\n",
      "[Epoch 58/100] [Batch 0/870] [loss: 0.009146]\n",
      "[Epoch 58/100] [Batch 100/870] [loss: 0.178335]\n",
      "[Epoch 58/100] [Batch 200/870] [loss: 0.001734]\n",
      "[Epoch 58/100] [Batch 300/870] [loss: 0.158034]\n",
      "[Epoch 58/100] [Batch 400/870] [loss: 0.002803]\n",
      "[Epoch 58/100] [Batch 500/870] [loss: 0.001233]\n",
      "[Epoch 58/100] [Batch 600/870] [loss: 0.001102]\n",
      "[Epoch 58/100] [Batch 700/870] [loss: 0.002161]\n",
      "[Epoch 58/100] [Batch 800/870] [loss: 0.002496]\n",
      "-----[Epoch 58/100] [avg_train_loss: 0.015583]-----\n",
      "validation loss: 3.4621074199676514\n",
      "validation loss: 20.899959564208984\n",
      "validation loss: 5.206538200378418\n",
      "-----[val_avg_loss 12.602733]-----\n",
      "EarlyStopping counter: 12 out of 40\n",
      "[Epoch 59/100] [Batch 0/870] [loss: 0.006945]\n",
      "[Epoch 59/100] [Batch 100/870] [loss: 0.003402]\n",
      "[Epoch 59/100] [Batch 200/870] [loss: 0.004188]\n",
      "[Epoch 59/100] [Batch 300/870] [loss: 0.121718]\n",
      "[Epoch 59/100] [Batch 400/870] [loss: 0.021167]\n",
      "[Epoch 59/100] [Batch 500/870] [loss: 0.005430]\n",
      "[Epoch 59/100] [Batch 600/870] [loss: 0.004553]\n",
      "[Epoch 59/100] [Batch 700/870] [loss: 0.004868]\n",
      "[Epoch 59/100] [Batch 800/870] [loss: 0.163687]\n",
      "-----[Epoch 59/100] [avg_train_loss: 0.000054]-----\n",
      "validation loss: 14.551013946533203\n",
      "validation loss: 20.464508056640625\n",
      "validation loss: 39.143009185791016\n",
      "-----[val_avg_loss 12.808102]-----\n",
      "EarlyStopping counter: 13 out of 40\n",
      "[Epoch 60/100] [Batch 0/870] [loss: 0.059222]\n",
      "[Epoch 60/100] [Batch 100/870] [loss: 0.002698]\n",
      "[Epoch 60/100] [Batch 200/870] [loss: 0.003708]\n",
      "[Epoch 60/100] [Batch 300/870] [loss: 0.002971]\n",
      "[Epoch 60/100] [Batch 400/870] [loss: 0.013617]\n",
      "[Epoch 60/100] [Batch 500/870] [loss: 0.077594]\n",
      "[Epoch 60/100] [Batch 600/870] [loss: 0.136088]\n",
      "[Epoch 60/100] [Batch 700/870] [loss: 0.151573]\n",
      "[Epoch 60/100] [Batch 800/870] [loss: 0.009681]\n",
      "-----[Epoch 60/100] [avg_train_loss: 0.000026]-----\n",
      "validation loss: 23.87285614013672\n",
      "validation loss: 12.450746536254883\n",
      "validation loss: 7.404895305633545\n",
      "-----[val_avg_loss 12.837570]-----\n",
      "EarlyStopping counter: 14 out of 40\n",
      "[Epoch 61/100] [Batch 0/870] [loss: 0.000829]\n",
      "[Epoch 61/100] [Batch 100/870] [loss: 0.010757]\n",
      "[Epoch 61/100] [Batch 200/870] [loss: 0.013480]\n",
      "[Epoch 61/100] [Batch 300/870] [loss: 0.008352]\n",
      "[Epoch 61/100] [Batch 400/870] [loss: 0.003947]\n",
      "[Epoch 61/100] [Batch 500/870] [loss: 0.001901]\n",
      "[Epoch 61/100] [Batch 600/870] [loss: 0.000035]\n",
      "[Epoch 61/100] [Batch 700/870] [loss: 0.010438]\n",
      "[Epoch 61/100] [Batch 800/870] [loss: 0.112932]\n",
      "-----[Epoch 61/100] [avg_train_loss: 0.741142]-----\n",
      "validation loss: 32.25216293334961\n",
      "validation loss: 15.829371452331543\n",
      "validation loss: 2.8620848655700684\n",
      "-----[val_avg_loss 12.905498]-----\n",
      "EarlyStopping counter: 15 out of 40\n",
      "[Epoch 62/100] [Batch 0/870] [loss: 1.405592]\n",
      "[Epoch 62/100] [Batch 100/870] [loss: 0.001556]\n",
      "[Epoch 62/100] [Batch 200/870] [loss: 0.011749]\n",
      "[Epoch 62/100] [Batch 300/870] [loss: 0.003922]\n",
      "[Epoch 62/100] [Batch 400/870] [loss: 0.000127]\n",
      "[Epoch 62/100] [Batch 500/870] [loss: 0.058069]\n",
      "[Epoch 62/100] [Batch 600/870] [loss: 0.000325]\n",
      "[Epoch 62/100] [Batch 700/870] [loss: 0.063698]\n",
      "[Epoch 62/100] [Batch 800/870] [loss: 0.016730]\n",
      "-----[Epoch 62/100] [avg_train_loss: 0.000018]-----\n",
      "validation loss: 31.747657775878906\n",
      "validation loss: 9.233904838562012\n",
      "validation loss: 0.8593067526817322\n",
      "-----[val_avg_loss 12.922296]-----\n",
      "EarlyStopping counter: 16 out of 40\n",
      "[Epoch 63/100] [Batch 0/870] [loss: 0.002343]\n",
      "[Epoch 63/100] [Batch 100/870] [loss: 0.004752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63/100] [Batch 200/870] [loss: 0.001999]\n",
      "[Epoch 63/100] [Batch 300/870] [loss: 0.197921]\n",
      "[Epoch 63/100] [Batch 400/870] [loss: 0.000082]\n",
      "[Epoch 63/100] [Batch 500/870] [loss: 0.000945]\n",
      "[Epoch 63/100] [Batch 600/870] [loss: 0.091088]\n",
      "[Epoch 63/100] [Batch 700/870] [loss: 0.152571]\n",
      "[Epoch 63/100] [Batch 800/870] [loss: 0.001362]\n",
      "-----[Epoch 63/100] [avg_train_loss: 0.001566]-----\n",
      "validation loss: 33.45314407348633\n",
      "validation loss: 3.460793972015381\n",
      "validation loss: 0.11449095606803894\n",
      "-----[val_avg_loss 12.913098]-----\n",
      "EarlyStopping counter: 17 out of 40\n",
      "[Epoch 64/100] [Batch 0/870] [loss: 0.000640]\n",
      "[Epoch 64/100] [Batch 100/870] [loss: 0.002322]\n",
      "[Epoch 64/100] [Batch 200/870] [loss: 0.134725]\n",
      "[Epoch 64/100] [Batch 300/870] [loss: 0.033613]\n",
      "[Epoch 64/100] [Batch 400/870] [loss: 0.000338]\n",
      "[Epoch 64/100] [Batch 500/870] [loss: 0.234537]\n",
      "[Epoch 64/100] [Batch 600/870] [loss: 0.042622]\n",
      "[Epoch 64/100] [Batch 700/870] [loss: 0.046744]\n",
      "[Epoch 64/100] [Batch 800/870] [loss: 0.002868]\n",
      "-----[Epoch 64/100] [avg_train_loss: 0.002756]-----\n",
      "validation loss: 7.014509201049805\n",
      "validation loss: 16.768375396728516\n",
      "validation loss: 2.806164264678955\n",
      "-----[val_avg_loss 12.849815]-----\n",
      "EarlyStopping counter: 18 out of 40\n",
      "[Epoch 65/100] [Batch 0/870] [loss: 0.026307]\n",
      "[Epoch 65/100] [Batch 100/870] [loss: 0.013866]\n",
      "[Epoch 65/100] [Batch 200/870] [loss: 0.046355]\n",
      "[Epoch 65/100] [Batch 300/870] [loss: 0.000576]\n",
      "[Epoch 65/100] [Batch 400/870] [loss: 0.000476]\n",
      "[Epoch 65/100] [Batch 500/870] [loss: 0.001925]\n",
      "[Epoch 65/100] [Batch 600/870] [loss: 0.001829]\n",
      "[Epoch 65/100] [Batch 700/870] [loss: 0.008881]\n",
      "[Epoch 65/100] [Batch 800/870] [loss: 0.002072]\n",
      "-----[Epoch 65/100] [avg_train_loss: 0.119403]-----\n",
      "validation loss: 34.047332763671875\n",
      "validation loss: 13.206944465637207\n",
      "validation loss: 23.211824417114258\n",
      "-----[val_avg_loss 13.013490]-----\n",
      "EarlyStopping counter: 19 out of 40\n",
      "[Epoch 66/100] [Batch 0/870] [loss: 0.003880]\n",
      "[Epoch 66/100] [Batch 100/870] [loss: 0.000877]\n",
      "[Epoch 66/100] [Batch 200/870] [loss: 0.000683]\n",
      "[Epoch 66/100] [Batch 300/870] [loss: 0.006133]\n",
      "[Epoch 66/100] [Batch 400/870] [loss: 0.626755]\n",
      "[Epoch 66/100] [Batch 500/870] [loss: 0.000173]\n",
      "[Epoch 66/100] [Batch 600/870] [loss: 0.426249]\n",
      "[Epoch 66/100] [Batch 700/870] [loss: 0.007529]\n",
      "[Epoch 66/100] [Batch 800/870] [loss: 0.355178]\n",
      "-----[Epoch 66/100] [avg_train_loss: 0.000717]-----\n",
      "validation loss: 4.683398723602295\n",
      "validation loss: 28.453800201416016\n",
      "validation loss: 13.979741096496582\n",
      "-----[val_avg_loss 13.054281]-----\n",
      "EarlyStopping counter: 20 out of 40\n",
      "[Epoch 67/100] [Batch 0/870] [loss: 0.000811]\n",
      "[Epoch 67/100] [Batch 100/870] [loss: 0.008780]\n",
      "[Epoch 67/100] [Batch 200/870] [loss: 0.000410]\n",
      "[Epoch 67/100] [Batch 300/870] [loss: 0.011246]\n",
      "[Epoch 67/100] [Batch 400/870] [loss: 0.017506]\n",
      "[Epoch 67/100] [Batch 500/870] [loss: 0.000083]\n",
      "[Epoch 67/100] [Batch 600/870] [loss: 0.012845]\n",
      "[Epoch 67/100] [Batch 700/870] [loss: 0.004675]\n",
      "[Epoch 67/100] [Batch 800/870] [loss: 0.003101]\n",
      "-----[Epoch 67/100] [avg_train_loss: 0.119115]-----\n",
      "validation loss: 9.598151206970215\n",
      "validation loss: 13.976491928100586\n",
      "validation loss: 2.117373466491699\n",
      "-----[val_avg_loss 12.987262]-----\n",
      "EarlyStopping counter: 21 out of 40\n",
      "[Epoch 68/100] [Batch 0/870] [loss: 0.007388]\n",
      "[Epoch 68/100] [Batch 100/870] [loss: 0.443140]\n",
      "[Epoch 68/100] [Batch 200/870] [loss: 0.000133]\n",
      "[Epoch 68/100] [Batch 300/870] [loss: 0.009301]\n",
      "[Epoch 68/100] [Batch 400/870] [loss: 0.298525]\n",
      "[Epoch 68/100] [Batch 500/870] [loss: 0.000061]\n",
      "[Epoch 68/100] [Batch 600/870] [loss: 0.000157]\n",
      "[Epoch 68/100] [Batch 700/870] [loss: 0.007166]\n",
      "[Epoch 68/100] [Batch 800/870] [loss: 0.006975]\n",
      "-----[Epoch 68/100] [avg_train_loss: 0.002012]-----\n",
      "validation loss: 0.19355981051921844\n",
      "validation loss: 20.464221954345703\n",
      "validation loss: 26.96847152709961\n",
      "-----[val_avg_loss 13.029735]-----\n",
      "EarlyStopping counter: 22 out of 40\n",
      "[Epoch 69/100] [Batch 0/870] [loss: 0.000804]\n",
      "[Epoch 69/100] [Batch 100/870] [loss: 0.010817]\n",
      "[Epoch 69/100] [Batch 200/870] [loss: 0.074381]\n",
      "[Epoch 69/100] [Batch 300/870] [loss: 0.016198]\n",
      "[Epoch 69/100] [Batch 400/870] [loss: 0.013920]\n",
      "[Epoch 69/100] [Batch 500/870] [loss: 0.008120]\n",
      "[Epoch 69/100] [Batch 600/870] [loss: 0.006018]\n",
      "[Epoch 69/100] [Batch 700/870] [loss: 0.000314]\n",
      "[Epoch 69/100] [Batch 800/870] [loss: 0.021191]\n",
      "-----[Epoch 69/100] [avg_train_loss: 0.006211]-----\n",
      "validation loss: 2.6696858406066895\n",
      "validation loss: 26.303081512451172\n",
      "validation loss: 3.28885817527771\n",
      "-----[val_avg_loss 12.996751]-----\n",
      "EarlyStopping counter: 23 out of 40\n",
      "[Epoch 70/100] [Batch 0/870] [loss: 0.148354]\n",
      "[Epoch 70/100] [Batch 100/870] [loss: 0.018108]\n",
      "[Epoch 70/100] [Batch 200/870] [loss: 0.100781]\n",
      "[Epoch 70/100] [Batch 300/870] [loss: 0.011604]\n",
      "[Epoch 70/100] [Batch 400/870] [loss: 0.055123]\n",
      "[Epoch 70/100] [Batch 500/870] [loss: 0.001934]\n",
      "[Epoch 70/100] [Batch 600/870] [loss: 0.041542]\n",
      "[Epoch 70/100] [Batch 700/870] [loss: 0.006391]\n",
      "[Epoch 70/100] [Batch 800/870] [loss: 0.009714]\n",
      "-----[Epoch 70/100] [avg_train_loss: 0.054818]-----\n",
      "validation loss: 0.01294859778136015\n",
      "validation loss: 5.933285713195801\n",
      "validation loss: 21.470943450927734\n",
      "-----[val_avg_loss 12.941641]-----\n",
      "EarlyStopping counter: 24 out of 40\n",
      "[Epoch 71/100] [Batch 0/870] [loss: 0.002901]\n",
      "[Epoch 71/100] [Batch 100/870] [loss: 0.002561]\n",
      "[Epoch 71/100] [Batch 200/870] [loss: 0.138252]\n",
      "[Epoch 71/100] [Batch 300/870] [loss: 0.028192]\n",
      "[Epoch 71/100] [Batch 400/870] [loss: 0.179577]\n",
      "[Epoch 71/100] [Batch 500/870] [loss: 0.057176]\n",
      "[Epoch 71/100] [Batch 600/870] [loss: 0.003403]\n",
      "[Epoch 71/100] [Batch 700/870] [loss: 0.004919]\n",
      "[Epoch 71/100] [Batch 800/870] [loss: 0.001823]\n",
      "-----[Epoch 71/100] [avg_train_loss: 0.000173]-----\n",
      "validation loss: 38.40019226074219\n",
      "validation loss: 4.9443840980529785\n",
      "validation loss: 0.0007900159107521176\n",
      "-----[val_avg_loss 12.962864]-----\n",
      "EarlyStopping counter: 25 out of 40\n",
      "[Epoch 72/100] [Batch 0/870] [loss: 0.013953]\n",
      "[Epoch 72/100] [Batch 100/870] [loss: 0.004636]\n",
      "[Epoch 72/100] [Batch 200/870] [loss: 0.004715]\n",
      "[Epoch 72/100] [Batch 300/870] [loss: 0.007643]\n",
      "[Epoch 72/100] [Batch 400/870] [loss: 0.000051]\n",
      "[Epoch 72/100] [Batch 500/870] [loss: 0.000144]\n",
      "[Epoch 72/100] [Batch 600/870] [loss: 0.000095]\n",
      "[Epoch 72/100] [Batch 700/870] [loss: 0.000597]\n",
      "[Epoch 72/100] [Batch 800/870] [loss: 0.015433]\n",
      "-----[Epoch 72/100] [avg_train_loss: 0.307369]-----\n",
      "validation loss: 62.55091094970703\n",
      "validation loss: 20.49659538269043\n",
      "validation loss: 11.079835891723633\n",
      "-----[val_avg_loss 13.218599]-----\n",
      "EarlyStopping counter: 26 out of 40\n",
      "[Epoch 73/100] [Batch 0/870] [loss: 0.000789]\n",
      "[Epoch 73/100] [Batch 100/870] [loss: 0.000500]\n",
      "[Epoch 73/100] [Batch 200/870] [loss: 0.011141]\n",
      "[Epoch 73/100] [Batch 300/870] [loss: 0.083883]\n",
      "[Epoch 73/100] [Batch 400/870] [loss: 0.003222]\n",
      "[Epoch 73/100] [Batch 500/870] [loss: 0.000554]\n",
      "[Epoch 73/100] [Batch 600/870] [loss: 0.000957]\n",
      "[Epoch 73/100] [Batch 700/870] [loss: 0.000831]\n",
      "[Epoch 73/100] [Batch 800/870] [loss: 0.003617]\n",
      "-----[Epoch 73/100] [avg_train_loss: 0.000069]-----\n",
      "validation loss: 3.851145029067993\n",
      "validation loss: 47.835227966308594\n",
      "validation loss: 16.277801513671875\n",
      "-----[val_avg_loss 13.347861]-----\n",
      "EarlyStopping counter: 27 out of 40\n",
      "[Epoch 74/100] [Batch 0/870] [loss: 0.010909]\n",
      "[Epoch 74/100] [Batch 100/870] [loss: 0.011791]\n",
      "[Epoch 74/100] [Batch 200/870] [loss: 0.248324]\n",
      "[Epoch 74/100] [Batch 300/870] [loss: 0.000375]\n",
      "[Epoch 74/100] [Batch 400/870] [loss: 0.000066]\n",
      "[Epoch 74/100] [Batch 500/870] [loss: 0.007360]\n",
      "[Epoch 74/100] [Batch 600/870] [loss: 0.000231]\n",
      "[Epoch 74/100] [Batch 700/870] [loss: 0.014704]\n",
      "[Epoch 74/100] [Batch 800/870] [loss: 0.007633]\n",
      "-----[Epoch 74/100] [avg_train_loss: 0.000016]-----\n",
      "validation loss: 44.19055938720703\n",
      "validation loss: 20.63349151611328\n",
      "validation loss: 0.0014715557917952538\n",
      "-----[val_avg_loss 13.459491]-----\n",
      "EarlyStopping counter: 28 out of 40\n",
      "[Epoch 75/100] [Batch 0/870] [loss: 0.004260]\n",
      "[Epoch 75/100] [Batch 100/870] [loss: 0.001445]\n",
      "[Epoch 75/100] [Batch 200/870] [loss: 0.093901]\n",
      "[Epoch 75/100] [Batch 300/870] [loss: 0.000080]\n",
      "[Epoch 75/100] [Batch 400/870] [loss: 0.000378]\n",
      "[Epoch 75/100] [Batch 500/870] [loss: 0.000208]\n",
      "[Epoch 75/100] [Batch 600/870] [loss: 0.003973]\n",
      "[Epoch 75/100] [Batch 700/870] [loss: 0.000395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 75/100] [Batch 800/870] [loss: 0.001419]\n",
      "-----[Epoch 75/100] [avg_train_loss: 0.000107]-----\n",
      "validation loss: 31.24398422241211\n",
      "validation loss: 4.570513725280762\n",
      "validation loss: 4.727726459503174\n",
      "-----[val_avg_loss 13.460219]-----\n",
      "EarlyStopping counter: 29 out of 40\n",
      "[Epoch 76/100] [Batch 0/870] [loss: 0.005334]\n",
      "[Epoch 76/100] [Batch 100/870] [loss: 0.000006]\n",
      "[Epoch 76/100] [Batch 200/870] [loss: 0.000088]\n",
      "[Epoch 76/100] [Batch 300/870] [loss: 0.721820]\n",
      "[Epoch 76/100] [Batch 400/870] [loss: 0.059646]\n",
      "[Epoch 76/100] [Batch 500/870] [loss: 0.003799]\n",
      "[Epoch 76/100] [Batch 600/870] [loss: 0.000370]\n",
      "[Epoch 76/100] [Batch 700/870] [loss: 0.000549]\n",
      "[Epoch 76/100] [Batch 800/870] [loss: 0.378900]\n",
      "-----[Epoch 76/100] [avg_train_loss: 0.002628]-----\n",
      "validation loss: 34.82727813720703\n",
      "validation loss: 18.985389709472656\n",
      "validation loss: 9.5768404006958\n",
      "-----[val_avg_loss 13.561135]-----\n",
      "EarlyStopping counter: 30 out of 40\n",
      "[Epoch 77/100] [Batch 0/870] [loss: 0.000573]\n",
      "[Epoch 77/100] [Batch 100/870] [loss: 0.001978]\n",
      "[Epoch 77/100] [Batch 200/870] [loss: 0.004288]\n",
      "[Epoch 77/100] [Batch 300/870] [loss: 0.000027]\n",
      "[Epoch 77/100] [Batch 400/870] [loss: 0.000013]\n",
      "[Epoch 77/100] [Batch 500/870] [loss: 0.064421]\n",
      "[Epoch 77/100] [Batch 600/870] [loss: 0.160911]\n",
      "[Epoch 77/100] [Batch 700/870] [loss: 0.003952]\n",
      "[Epoch 77/100] [Batch 800/870] [loss: 0.000028]\n",
      "-----[Epoch 77/100] [avg_train_loss: 0.000002]-----\n",
      "validation loss: 13.932889938354492\n",
      "validation loss: 36.22489929199219\n",
      "validation loss: 0.011930751614272594\n",
      "-----[val_avg_loss 13.602201]-----\n",
      "EarlyStopping counter: 31 out of 40\n",
      "[Epoch 78/100] [Batch 0/870] [loss: 0.000187]\n",
      "[Epoch 78/100] [Batch 100/870] [loss: 0.000158]\n",
      "[Epoch 78/100] [Batch 200/870] [loss: 0.002240]\n",
      "[Epoch 78/100] [Batch 300/870] [loss: 0.000497]\n",
      "[Epoch 78/100] [Batch 400/870] [loss: 0.000761]\n",
      "[Epoch 78/100] [Batch 500/870] [loss: 0.007932]\n",
      "[Epoch 78/100] [Batch 600/870] [loss: 0.003993]\n",
      "[Epoch 78/100] [Batch 700/870] [loss: 0.002676]\n",
      "[Epoch 78/100] [Batch 800/870] [loss: 0.001867]\n",
      "-----[Epoch 78/100] [avg_train_loss: 0.000407]-----\n",
      "validation loss: 8.857705116271973\n",
      "validation loss: 25.369752883911133\n",
      "validation loss: 0.07835037261247635\n",
      "-----[val_avg_loss 13.574420]-----\n",
      "EarlyStopping counter: 32 out of 40\n",
      "[Epoch 79/100] [Batch 0/870] [loss: 0.000483]\n",
      "[Epoch 79/100] [Batch 100/870] [loss: 0.000080]\n",
      "[Epoch 79/100] [Batch 200/870] [loss: 0.000129]\n",
      "[Epoch 79/100] [Batch 300/870] [loss: 0.000103]\n",
      "[Epoch 79/100] [Batch 400/870] [loss: 0.006189]\n",
      "[Epoch 79/100] [Batch 500/870] [loss: 0.000015]\n",
      "[Epoch 79/100] [Batch 600/870] [loss: 0.005367]\n",
      "[Epoch 79/100] [Batch 700/870] [loss: 0.000400]\n",
      "[Epoch 79/100] [Batch 800/870] [loss: 0.130911]\n",
      "-----[Epoch 79/100] [avg_train_loss: 0.125635]-----\n",
      "validation loss: 0.15866033732891083\n",
      "validation loss: 16.013397216796875\n",
      "validation loss: 5.024065017700195\n",
      "-----[val_avg_loss 13.492027]-----\n",
      "EarlyStopping counter: 33 out of 40\n",
      "[Epoch 80/100] [Batch 0/870] [loss: 0.002973]\n",
      "[Epoch 80/100] [Batch 100/870] [loss: 0.027748]\n",
      "[Epoch 80/100] [Batch 200/870] [loss: 0.001009]\n",
      "[Epoch 80/100] [Batch 300/870] [loss: 0.000234]\n",
      "[Epoch 80/100] [Batch 400/870] [loss: 0.035038]\n",
      "[Epoch 80/100] [Batch 500/870] [loss: 0.002059]\n",
      "[Epoch 80/100] [Batch 600/870] [loss: 0.002854]\n",
      "[Epoch 80/100] [Batch 700/870] [loss: 0.001204]\n",
      "[Epoch 80/100] [Batch 800/870] [loss: 0.000083]\n",
      "-----[Epoch 80/100] [avg_train_loss: 0.000100]-----\n",
      "validation loss: 36.59940719604492\n",
      "validation loss: 16.867326736450195\n",
      "validation loss: 23.207590103149414\n",
      "-----[val_avg_loss 13.642853]-----\n",
      "EarlyStopping counter: 34 out of 40\n",
      "[Epoch 81/100] [Batch 0/870] [loss: 0.000469]\n",
      "[Epoch 81/100] [Batch 100/870] [loss: 0.022476]\n",
      "[Epoch 81/100] [Batch 200/870] [loss: 0.010527]\n",
      "[Epoch 81/100] [Batch 300/870] [loss: 0.003348]\n",
      "[Epoch 81/100] [Batch 400/870] [loss: 0.004421]\n",
      "[Epoch 81/100] [Batch 500/870] [loss: 0.005993]\n",
      "[Epoch 81/100] [Batch 600/870] [loss: 0.000852]\n",
      "[Epoch 81/100] [Batch 700/870] [loss: 0.210075]\n",
      "[Epoch 81/100] [Batch 800/870] [loss: 0.013204]\n",
      "-----[Epoch 81/100] [avg_train_loss: 0.018978]-----\n",
      "validation loss: 20.832855224609375\n",
      "validation loss: 5.820993423461914\n",
      "validation loss: 7.69792366027832\n",
      "-----[val_avg_loss 13.615788]-----\n",
      "EarlyStopping counter: 35 out of 40\n",
      "[Epoch 82/100] [Batch 0/870] [loss: 0.032070]\n",
      "[Epoch 82/100] [Batch 100/870] [loss: 0.003325]\n",
      "[Epoch 82/100] [Batch 200/870] [loss: 0.005070]\n",
      "[Epoch 82/100] [Batch 300/870] [loss: 0.000028]\n",
      "[Epoch 82/100] [Batch 400/870] [loss: 0.003260]\n",
      "[Epoch 82/100] [Batch 500/870] [loss: 0.012510]\n",
      "[Epoch 82/100] [Batch 600/870] [loss: 0.001568]\n",
      "[Epoch 82/100] [Batch 700/870] [loss: 0.020508]\n",
      "[Epoch 82/100] [Batch 800/870] [loss: 0.001890]\n",
      "-----[Epoch 82/100] [avg_train_loss: 0.001096]-----\n",
      "validation loss: 26.79930877685547\n",
      "validation loss: 25.370119094848633\n",
      "validation loss: 8.339263916015625\n",
      "-----[val_avg_loss 13.695712]-----\n",
      "EarlyStopping counter: 36 out of 40\n",
      "[Epoch 83/100] [Batch 0/870] [loss: 0.000542]\n",
      "[Epoch 83/100] [Batch 100/870] [loss: 0.000124]\n",
      "[Epoch 83/100] [Batch 200/870] [loss: 0.000111]\n",
      "[Epoch 83/100] [Batch 300/870] [loss: 0.079802]\n",
      "[Epoch 83/100] [Batch 400/870] [loss: 0.003266]\n",
      "[Epoch 83/100] [Batch 500/870] [loss: 0.000331]\n",
      "[Epoch 83/100] [Batch 600/870] [loss: 0.022033]\n",
      "[Epoch 83/100] [Batch 700/870] [loss: 0.089619]\n",
      "[Epoch 83/100] [Batch 800/870] [loss: 0.024045]\n",
      "-----[Epoch 83/100] [avg_train_loss: 0.000256]-----\n",
      "validation loss: 0.09935051202774048\n",
      "validation loss: 4.783930778503418\n",
      "validation loss: 14.714189529418945\n",
      "-----[val_avg_loss 13.609408]-----\n",
      "EarlyStopping counter: 37 out of 40\n",
      "[Epoch 84/100] [Batch 0/870] [loss: 0.016798]\n",
      "[Epoch 84/100] [Batch 100/870] [loss: 0.010475]\n",
      "[Epoch 84/100] [Batch 200/870] [loss: 0.012456]\n",
      "[Epoch 84/100] [Batch 300/870] [loss: 0.001605]\n",
      "[Epoch 84/100] [Batch 400/870] [loss: 0.110655]\n",
      "[Epoch 84/100] [Batch 500/870] [loss: 0.014757]\n",
      "[Epoch 84/100] [Batch 600/870] [loss: 0.021203]\n",
      "[Epoch 84/100] [Batch 700/870] [loss: 0.061091]\n",
      "[Epoch 84/100] [Batch 800/870] [loss: 0.031728]\n",
      "-----[Epoch 84/100] [avg_train_loss: 0.001135]-----\n",
      "validation loss: 24.536724090576172\n",
      "validation loss: 22.79367446899414\n",
      "validation loss: 0.0014622732996940613\n",
      "-----[val_avg_loss 13.635217]-----\n",
      "EarlyStopping counter: 38 out of 40\n",
      "[Epoch 85/100] [Batch 0/870] [loss: 0.003514]\n",
      "[Epoch 85/100] [Batch 100/870] [loss: 0.000915]\n",
      "[Epoch 85/100] [Batch 200/870] [loss: 0.080980]\n",
      "[Epoch 85/100] [Batch 300/870] [loss: 0.003043]\n",
      "[Epoch 85/100] [Batch 400/870] [loss: 0.000229]\n",
      "[Epoch 85/100] [Batch 500/870] [loss: 0.004109]\n",
      "[Epoch 85/100] [Batch 600/870] [loss: 0.000212]\n",
      "[Epoch 85/100] [Batch 700/870] [loss: 0.003037]\n",
      "[Epoch 85/100] [Batch 800/870] [loss: 0.000288]\n",
      "-----[Epoch 85/100] [avg_train_loss: 0.000604]-----\n",
      "validation loss: 24.76470375061035\n",
      "validation loss: 31.908750534057617\n",
      "validation loss: 0.35202184319496155\n",
      "-----[val_avg_loss 13.698432]-----\n",
      "EarlyStopping counter: 39 out of 40\n",
      "[Epoch 86/100] [Batch 0/870] [loss: 0.048668]\n",
      "[Epoch 86/100] [Batch 100/870] [loss: 0.000268]\n",
      "[Epoch 86/100] [Batch 200/870] [loss: 0.000847]\n",
      "[Epoch 86/100] [Batch 300/870] [loss: 0.000493]\n",
      "[Epoch 86/100] [Batch 400/870] [loss: 0.001121]\n",
      "[Epoch 86/100] [Batch 500/870] [loss: 0.000104]\n",
      "[Epoch 86/100] [Batch 600/870] [loss: 0.000223]\n",
      "[Epoch 86/100] [Batch 700/870] [loss: 0.000029]\n",
      "[Epoch 86/100] [Batch 800/870] [loss: 0.000051]\n",
      "-----[Epoch 86/100] [avg_train_loss: 0.000011]-----\n",
      "validation loss: 7.5924787521362305\n",
      "validation loss: 31.747352600097656\n",
      "validation loss: 0.0002732210559770465\n",
      "-----[val_avg_loss 13.691628]-----\n",
      "Validation loss decreased (0.000468 --> 0.000273).  Saving model ...\n",
      "[Epoch 87/100] [Batch 0/870] [loss: 0.001301]\n",
      "[Epoch 87/100] [Batch 100/870] [loss: 0.054912]\n",
      "[Epoch 87/100] [Batch 200/870] [loss: 0.001051]\n",
      "[Epoch 87/100] [Batch 300/870] [loss: 0.081765]\n",
      "[Epoch 87/100] [Batch 400/870] [loss: 0.001104]\n",
      "[Epoch 87/100] [Batch 500/870] [loss: 0.002179]\n",
      "[Epoch 87/100] [Batch 600/870] [loss: 0.001208]\n",
      "[Epoch 87/100] [Batch 700/870] [loss: 0.006078]\n",
      "[Epoch 87/100] [Batch 800/870] [loss: 0.012048]\n",
      "-----[Epoch 87/100] [avg_train_loss: 0.000044]-----\n",
      "validation loss: 16.98271942138672\n",
      "validation loss: 30.67687225341797\n",
      "validation loss: 0.00370657816529274\n",
      "-----[val_avg_loss 13.716871]-----\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 88/100] [Batch 0/870] [loss: 0.005202]\n",
      "[Epoch 88/100] [Batch 100/870] [loss: 0.010602]\n",
      "[Epoch 88/100] [Batch 200/870] [loss: 0.192433]\n",
      "[Epoch 88/100] [Batch 300/870] [loss: 0.000370]\n",
      "[Epoch 88/100] [Batch 400/870] [loss: 0.094861]\n",
      "[Epoch 88/100] [Batch 500/870] [loss: 0.000211]\n",
      "[Epoch 88/100] [Batch 600/870] [loss: 0.000005]\n",
      "[Epoch 88/100] [Batch 700/870] [loss: 0.008243]\n",
      "[Epoch 88/100] [Batch 800/870] [loss: 0.003923]\n",
      "-----[Epoch 88/100] [avg_train_loss: 0.004831]-----\n",
      "validation loss: 2.0508503913879395\n",
      "validation loss: 5.369868755340576\n",
      "validation loss: 24.138805389404297\n",
      "-----[val_avg_loss 13.680542]-----\n",
      "EarlyStopping counter: 2 out of 40\n",
      "[Epoch 89/100] [Batch 0/870] [loss: 0.003474]\n",
      "[Epoch 89/100] [Batch 100/870] [loss: 0.002643]\n",
      "[Epoch 89/100] [Batch 200/870] [loss: 0.006217]\n",
      "[Epoch 89/100] [Batch 300/870] [loss: 0.013792]\n",
      "[Epoch 89/100] [Batch 400/870] [loss: 0.002111]\n",
      "[Epoch 89/100] [Batch 500/870] [loss: 0.000390]\n",
      "[Epoch 89/100] [Batch 600/870] [loss: 0.238088]\n",
      "[Epoch 89/100] [Batch 700/870] [loss: 0.001501]\n",
      "[Epoch 89/100] [Batch 800/870] [loss: 0.005632]\n",
      "-----[Epoch 89/100] [avg_train_loss: 0.000009]-----\n",
      "validation loss: 25.406417846679688\n",
      "validation loss: 34.83549880981445\n",
      "validation loss: 5.57257604598999\n",
      "-----[val_avg_loss 13.773324]-----\n",
      "EarlyStopping counter: 3 out of 40\n",
      "[Epoch 90/100] [Batch 0/870] [loss: 0.000629]\n",
      "[Epoch 90/100] [Batch 100/870] [loss: 0.012902]\n",
      "[Epoch 90/100] [Batch 200/870] [loss: 0.015835]\n",
      "[Epoch 90/100] [Batch 300/870] [loss: 0.000672]\n",
      "[Epoch 90/100] [Batch 400/870] [loss: 0.003115]\n",
      "[Epoch 90/100] [Batch 500/870] [loss: 0.000598]\n",
      "[Epoch 90/100] [Batch 600/870] [loss: 0.021445]\n",
      "[Epoch 90/100] [Batch 700/870] [loss: 0.019141]\n",
      "[Epoch 90/100] [Batch 800/870] [loss: 0.011605]\n",
      "-----[Epoch 90/100] [avg_train_loss: 0.013766]-----\n",
      "validation loss: 36.567928314208984\n",
      "validation loss: 2.6028594970703125\n",
      "validation loss: 7.860687732696533\n",
      "-----[val_avg_loss 13.794478]-----\n",
      "EarlyStopping counter: 4 out of 40\n",
      "[Epoch 91/100] [Batch 0/870] [loss: 0.000447]\n",
      "[Epoch 91/100] [Batch 100/870] [loss: 0.000054]\n",
      "[Epoch 91/100] [Batch 200/870] [loss: 0.001339]\n",
      "[Epoch 91/100] [Batch 300/870] [loss: 0.156668]\n",
      "[Epoch 91/100] [Batch 400/870] [loss: 0.009740]\n",
      "[Epoch 91/100] [Batch 500/870] [loss: 0.006011]\n",
      "[Epoch 91/100] [Batch 600/870] [loss: 0.001079]\n",
      "[Epoch 91/100] [Batch 700/870] [loss: 0.003487]\n",
      "[Epoch 91/100] [Batch 800/870] [loss: 0.026946]\n",
      "-----[Epoch 91/100] [avg_train_loss: 0.000028]-----\n",
      "validation loss: 7.110672950744629\n",
      "validation loss: 9.791427612304688\n",
      "validation loss: 30.766529083251953\n",
      "-----[val_avg_loss 13.817500]-----\n",
      "EarlyStopping counter: 5 out of 40\n",
      "[Epoch 92/100] [Batch 0/870] [loss: 0.000882]\n",
      "[Epoch 92/100] [Batch 100/870] [loss: 0.000939]\n",
      "[Epoch 92/100] [Batch 200/870] [loss: 0.122853]\n",
      "[Epoch 92/100] [Batch 300/870] [loss: 0.000170]\n",
      "[Epoch 92/100] [Batch 400/870] [loss: 0.010378]\n",
      "[Epoch 92/100] [Batch 500/870] [loss: 0.000076]\n",
      "[Epoch 92/100] [Batch 600/870] [loss: 0.000064]\n",
      "[Epoch 92/100] [Batch 700/870] [loss: 0.000711]\n",
      "[Epoch 92/100] [Batch 800/870] [loss: 0.000877]\n",
      "-----[Epoch 92/100] [avg_train_loss: 0.000845]-----\n",
      "validation loss: 22.306699752807617\n",
      "validation loss: 16.917810440063477\n",
      "validation loss: 18.093894958496094\n",
      "-----[val_avg_loss 13.874985]-----\n",
      "EarlyStopping counter: 6 out of 40\n",
      "[Epoch 93/100] [Batch 0/870] [loss: 0.001705]\n",
      "[Epoch 93/100] [Batch 100/870] [loss: 0.000053]\n",
      "[Epoch 93/100] [Batch 200/870] [loss: 0.005184]\n",
      "[Epoch 93/100] [Batch 300/870] [loss: 0.000375]\n",
      "[Epoch 93/100] [Batch 400/870] [loss: 0.019079]\n",
      "[Epoch 93/100] [Batch 500/870] [loss: 0.043891]\n",
      "[Epoch 93/100] [Batch 600/870] [loss: 0.003382]\n",
      "[Epoch 93/100] [Batch 700/870] [loss: 0.000596]\n",
      "[Epoch 93/100] [Batch 800/870] [loss: 0.000002]\n",
      "-----[Epoch 93/100] [avg_train_loss: 0.040228]-----\n",
      "validation loss: 7.3301310539245605\n",
      "validation loss: 23.30545425415039\n",
      "validation loss: 0.062223486602306366\n",
      "-----[val_avg_loss 13.835820]-----\n",
      "EarlyStopping counter: 7 out of 40\n",
      "[Epoch 94/100] [Batch 0/870] [loss: 0.003128]\n",
      "[Epoch 94/100] [Batch 100/870] [loss: 0.000143]\n",
      "[Epoch 94/100] [Batch 200/870] [loss: 0.000661]\n",
      "[Epoch 94/100] [Batch 300/870] [loss: 0.003031]\n",
      "[Epoch 94/100] [Batch 400/870] [loss: 0.001641]\n",
      "[Epoch 94/100] [Batch 500/870] [loss: 0.000013]\n",
      "[Epoch 94/100] [Batch 600/870] [loss: 0.000365]\n",
      "[Epoch 94/100] [Batch 700/870] [loss: 0.003234]\n",
      "[Epoch 94/100] [Batch 800/870] [loss: 0.000238]\n",
      "-----[Epoch 94/100] [avg_train_loss: 0.012570]-----\n",
      "validation loss: 24.23651885986328\n",
      "validation loss: 3.6019887924194336\n",
      "validation loss: 44.48924255371094\n",
      "-----[val_avg_loss 13.945112]-----\n",
      "EarlyStopping counter: 8 out of 40\n",
      "[Epoch 95/100] [Batch 0/870] [loss: 0.000806]\n",
      "[Epoch 95/100] [Batch 100/870] [loss: 0.018174]\n",
      "[Epoch 95/100] [Batch 200/870] [loss: 0.000063]\n",
      "[Epoch 95/100] [Batch 300/870] [loss: 0.001274]\n",
      "[Epoch 95/100] [Batch 400/870] [loss: 0.003031]\n",
      "[Epoch 95/100] [Batch 500/870] [loss: 0.000213]\n",
      "[Epoch 95/100] [Batch 600/870] [loss: 0.000631]\n",
      "[Epoch 95/100] [Batch 700/870] [loss: 0.000259]\n",
      "[Epoch 95/100] [Batch 800/870] [loss: 0.000367]\n",
      "-----[Epoch 95/100] [avg_train_loss: 0.006407]-----\n",
      "validation loss: 48.20137405395508\n",
      "validation loss: 17.561655044555664\n",
      "validation loss: 28.15380096435547\n",
      "-----[val_avg_loss 14.127854]-----\n",
      "EarlyStopping counter: 9 out of 40\n",
      "[Epoch 96/100] [Batch 0/870] [loss: 0.008731]\n",
      "[Epoch 96/100] [Batch 100/870] [loss: 0.000234]\n",
      "[Epoch 96/100] [Batch 200/870] [loss: 0.002181]\n",
      "[Epoch 96/100] [Batch 300/870] [loss: 0.005460]\n",
      "[Epoch 96/100] [Batch 400/870] [loss: 0.001393]\n",
      "[Epoch 96/100] [Batch 500/870] [loss: 0.016230]\n",
      "[Epoch 96/100] [Batch 600/870] [loss: 0.025683]\n",
      "[Epoch 96/100] [Batch 700/870] [loss: 0.000396]\n",
      "[Epoch 96/100] [Batch 800/870] [loss: 0.000268]\n",
      "-----[Epoch 96/100] [avg_train_loss: 0.006644]-----\n",
      "validation loss: 44.0611457824707\n",
      "validation loss: 10.234640121459961\n",
      "validation loss: 0.8004921078681946\n",
      "-----[val_avg_loss 14.171995]-----\n",
      "EarlyStopping counter: 10 out of 40\n",
      "[Epoch 97/100] [Batch 0/870] [loss: 0.000087]\n",
      "[Epoch 97/100] [Batch 100/870] [loss: 0.001364]\n",
      "[Epoch 97/100] [Batch 200/870] [loss: 0.023178]\n",
      "[Epoch 97/100] [Batch 300/870] [loss: 0.000117]\n",
      "[Epoch 97/100] [Batch 400/870] [loss: 0.001837]\n",
      "[Epoch 97/100] [Batch 500/870] [loss: 0.000444]\n",
      "[Epoch 97/100] [Batch 600/870] [loss: 0.001857]\n",
      "[Epoch 97/100] [Batch 700/870] [loss: 0.000046]\n",
      "[Epoch 97/100] [Batch 800/870] [loss: 0.000582]\n",
      "-----[Epoch 97/100] [avg_train_loss: 0.000956]-----\n",
      "validation loss: 0.9538866877555847\n",
      "validation loss: 1.860581636428833\n",
      "validation loss: 14.958520889282227\n",
      "-----[val_avg_loss 14.086968]-----\n",
      "EarlyStopping counter: 11 out of 40\n",
      "[Epoch 98/100] [Batch 0/870] [loss: 0.022620]\n",
      "[Epoch 98/100] [Batch 100/870] [loss: 0.002150]\n",
      "[Epoch 98/100] [Batch 200/870] [loss: 0.000079]\n",
      "[Epoch 98/100] [Batch 300/870] [loss: 0.000372]\n",
      "[Epoch 98/100] [Batch 400/870] [loss: 0.000006]\n",
      "[Epoch 98/100] [Batch 500/870] [loss: 0.001050]\n",
      "[Epoch 98/100] [Batch 600/870] [loss: 0.037365]\n",
      "[Epoch 98/100] [Batch 700/870] [loss: 0.000021]\n",
      "[Epoch 98/100] [Batch 800/870] [loss: 0.002108]\n",
      "-----[Epoch 98/100] [avg_train_loss: 0.000715]-----\n",
      "validation loss: 38.63038635253906\n",
      "validation loss: 30.721372604370117\n",
      "validation loss: 29.268178939819336\n",
      "-----[val_avg_loss 14.278665]-----\n",
      "EarlyStopping counter: 12 out of 40\n",
      "[Epoch 99/100] [Batch 0/870] [loss: 0.000166]\n",
      "[Epoch 99/100] [Batch 100/870] [loss: 0.000321]\n",
      "[Epoch 99/100] [Batch 200/870] [loss: 0.001017]\n",
      "[Epoch 99/100] [Batch 300/870] [loss: 0.000007]\n",
      "[Epoch 99/100] [Batch 400/870] [loss: 0.006916]\n",
      "[Epoch 99/100] [Batch 500/870] [loss: 0.000120]\n",
      "[Epoch 99/100] [Batch 600/870] [loss: 0.012843]\n",
      "[Epoch 99/100] [Batch 700/870] [loss: 0.002852]\n",
      "[Epoch 99/100] [Batch 800/870] [loss: 0.000282]\n",
      "-----[Epoch 99/100] [avg_train_loss: 0.000411]-----\n",
      "validation loss: 10.557037353515625\n",
      "validation loss: 6.616874694824219\n",
      "validation loss: 21.77744483947754\n",
      "-----[val_avg_loss 14.265586]-----\n",
      "EarlyStopping counter: 13 out of 40\n",
      "[Epoch 100/100] [Batch 0/870] [loss: 0.000326]\n",
      "[Epoch 100/100] [Batch 100/870] [loss: 0.000362]\n",
      "[Epoch 100/100] [Batch 200/870] [loss: 0.000162]\n",
      "[Epoch 100/100] [Batch 300/870] [loss: 0.000923]\n",
      "[Epoch 100/100] [Batch 400/870] [loss: 0.001308]\n",
      "[Epoch 100/100] [Batch 500/870] [loss: 0.004175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 100/100] [Batch 600/870] [loss: 0.001841]\n",
      "[Epoch 100/100] [Batch 700/870] [loss: 0.000851]\n",
      "[Epoch 100/100] [Batch 800/870] [loss: 0.000163]\n",
      "-----[Epoch 100/100] [avg_train_loss: 0.116199]-----\n",
      "validation loss: 18.77013397216797\n",
      "validation loss: 2.846834421157837\n",
      "validation loss: 0.0693703144788742\n",
      "-----[val_avg_loss 14.195218]-----\n",
      "EarlyStopping counter: 14 out of 40\n"
     ]
    }
   ],
   "source": [
    "## 5\n",
    "train_val(model_vit, train_data_loader, val_data_loader, optimizer,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "e2Ddk2KVUwdW"
   },
   "outputs": [],
   "source": [
    "def evaluate(model_vit, test_data_loader):\n",
    "    model_vit.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx,(img,target) in enumerate(test_data_loader):\n",
    "            img, target = img.cuda(), target.cuda()\n",
    "            output = model_vit(img)\n",
    "\n",
    "            # 배치 오차를 합산\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            print('test loss: ', test_loss)\n",
    "\n",
    "\n",
    "            # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_data_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_data_loader.dataset)\n",
    "\n",
    "    print('Epoch: [{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epochs, test_loss, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "96a-x8rFVEYU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  14.175180435180664\n",
      "test loss:  15.68332326412201\n",
      "test loss:  22.245993971824646\n",
      "test loss:  23.132773518562317\n",
      "test loss:  29.793816685676575\n",
      "test loss:  33.11590230464935\n",
      "test loss:  34.82793712615967\n",
      "test loss:  36.41619431972504\n",
      "test loss:  37.4918372631073\n",
      "test loss:  39.69332408905029\n",
      "test loss:  40.05107420682907\n",
      "test loss:  43.11215132474899\n",
      "test loss:  55.95081442594528\n",
      "test loss:  60.72455710172653\n",
      "test loss:  85.6560909152031\n",
      "test loss:  96.29649180173874\n",
      "test loss:  112.26405066251755\n",
      "test loss:  122.80559748411179\n",
      "test loss:  144.50718516111374\n",
      "test loss:  170.31282824277878\n",
      "test loss:  184.78570955991745\n",
      "test loss:  214.65224474668503\n",
      "test loss:  236.30214709043503\n",
      "test loss:  269.5859224200249\n",
      "test loss:  283.73496836423874\n",
      "test loss:  283.900126978755\n",
      "test loss:  286.7518022507429\n",
      "test loss:  287.3478495925665\n",
      "test loss:  294.0965773910284\n",
      "test loss:  294.1011264640838\n",
      "test loss:  302.52941015549004\n",
      "test loss:  304.30270949192345\n",
      "test loss:  304.3813646901399\n",
      "test loss:  305.58894406445324\n",
      "test loss:  306.3108213413507\n",
      "test loss:  310.7167428005487\n",
      "test loss:  316.9587314594537\n",
      "test loss:  316.98416023142636\n",
      "test loss:  329.24261264689267\n",
      "test loss:  329.48958762176335\n",
      "test loss:  329.4926367092412\n",
      "test loss:  332.12862136843614\n",
      "test loss:  336.5549347687047\n",
      "test loss:  342.7105915832799\n",
      "test loss:  342.99948015692644\n",
      "test loss:  346.9800554800313\n",
      "test loss:  356.29281392577104\n",
      "test loss:  358.2996751356404\n",
      "test loss:  364.7716619062703\n",
      "test loss:  367.9753378916066\n",
      "test loss:  369.2824763345998\n",
      "test loss:  372.8413514185231\n",
      "test loss:  373.3366751957219\n",
      "test loss:  387.92914917948656\n",
      "test loss:  387.93278139829636\n",
      "test loss:  389.5977616906166\n",
      "test loss:  393.4172971844673\n",
      "test loss:  393.85018742084503\n",
      "test loss:  393.85720644751564\n",
      "test loss:  409.37814055243507\n",
      "test loss:  409.3854963541962\n",
      "test loss:  413.30361983785406\n",
      "test loss:  413.31710626976565\n",
      "test loss:  413.7574863662012\n",
      "test loss:  422.4913387526758\n",
      "test loss:  439.12564279930666\n",
      "test loss:  440.0132175912149\n",
      "test loss:  448.3429466714151\n",
      "test loss:  449.1478760470636\n",
      "test loss:  449.4464757372625\n",
      "test loss:  449.4493171891663\n",
      "test loss:  450.6013180932496\n",
      "test loss:  451.00586700649\n",
      "test loss:  451.87711507291533\n",
      "test loss:  451.998341495404\n",
      "test loss:  452.01369347725995\n",
      "test loss:  452.13820273731835\n",
      "test loss:  452.19395907525904\n",
      "test loss:  454.7801938832272\n",
      "test loss:  464.61783750657924\n",
      "test loss:  464.878966915654\n",
      "test loss:  468.34387408499606\n",
      "test loss:  469.47553120856173\n",
      "test loss:  469.49206958455034\n",
      "test loss:  469.90298993629403\n",
      "test loss:  472.61781389755197\n",
      "test loss:  472.6669016641099\n",
      "test loss:  472.68351816316135\n",
      "test loss:  472.709374075057\n",
      "test loss:  473.02680716407485\n",
      "test loss:  473.0347816965077\n",
      "test loss:  473.04546648380347\n",
      "test loss:  473.09450158220716\n",
      "test loss:  474.3718208943028\n",
      "test loss:  477.364227500977\n",
      "test loss:  477.3729440115858\n",
      "test loss:  484.5156990431715\n",
      "test loss:  487.84401477803476\n",
      "test loss:  487.85337465186603\n",
      "test loss:  488.1092333414126\n",
      "test loss:  488.1255678378511\n",
      "test loss:  496.4851812564302\n",
      "test loss:  496.6371445201803\n",
      "test loss:  501.4289631389547\n",
      "Epoch: [100] Test Loss: 0.8036, Accuracy: 81.25%\n"
     ]
    }
   ],
   "source": [
    "evaluate(model_vit, test_data_loader)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP/nR4MV9IV9GngBCcORNLa",
   "collapsed_sections": [],
   "name": "ViT_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0577ffd73e934a51a6ade33a84f0e5a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14da05d2c90d4654b615a02b06f3300c",
      "placeholder": "​",
      "style": "IPY_MODEL_899749374ec9409eb47fe0cfffa92d63",
      "value": " 331M/331M [00:13&lt;00:00, 24.2MB/s]"
     }
    },
    "14da05d2c90d4654b615a02b06f3300c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a9a68e3453f4f12986038e8d062e10a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "44b501daa7304efab202931ae5123f13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70df47a42d8a47668bf09624ecf5c7d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_933fcfe2ce35408baa6c2613cb29229a",
      "placeholder": "​",
      "style": "IPY_MODEL_7b869e361b7949df8abbc53cfdc672ab",
      "value": "100%"
     }
    },
    "7b869e361b7949df8abbc53cfdc672ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82417fe9c98647f1ad03d1a7fe02ccf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70df47a42d8a47668bf09624ecf5c7d5",
       "IPY_MODEL_86c92460d09c478cb7cc756886faaa4b",
       "IPY_MODEL_0577ffd73e934a51a6ade33a84f0e5a3"
      ],
      "layout": "IPY_MODEL_44b501daa7304efab202931ae5123f13"
     }
    },
    "86c92460d09c478cb7cc756886faaa4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e58f83284fa94eefb9df3dbccb44747d",
      "max": 347469964,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2a9a68e3453f4f12986038e8d062e10a",
      "value": 347469964
     }
    },
    "899749374ec9409eb47fe0cfffa92d63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "933fcfe2ce35408baa6c2613cb29229a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e58f83284fa94eefb9df3dbccb44747d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
